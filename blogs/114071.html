<link rel="stylesheet" type="text/css" href="../css/blog.css"><div class="cloud-blog-detail-content-wrap the_height"><div class="cloud-blog-detail-content-wrap">
    <div class="cloud-blog-detail-content blog-content-block-0" id="blogContent">
        <p>原文:<a rel="nofollow" href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd">https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd</a></p><h1 class="graf graf--h3 graf--leading graf--title" style="font-size:42px;margin:0px;font-family:'medium-content-title-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-weight:400;line-height:1.25;white-space:normal;background-color:rgb(255,255,255);padding-top:16px;"><span>Apache Spark的深度学习 - 第1部分</span></h1><h2 class="graf graf--h4 graf-after--h3 graf--subtitle" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;font-weight:400;margin:5px 0px 22px;font-size:28px;line-height:1.22;white-space:normal;background-color:rgb(255,255,255);"><span><span>第一部分是关于如何使用Apache Spark进行分布式深度学习的完整讨论。</span><span>这一部分：什么是Spark，Spark + DL的基础知识以及更多内容。</span><span>你可以在这里红色第二部分：</span></span><a rel="nofollow" href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-2-2a2938a36d35" class="markup--anchor markup--h4-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px 1em;"><span><span>使用Apache Spark进行深度学习 - 第2部分</span></span></a><span>。</span></h2><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>第2部分可在此处获得：</span><a rel="nofollow" href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-2-2a2938a36d35" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>使用Apache Spark进行深度学习 - 第2部分</span></span></a><span>。</span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;white-space:normal;background-color:rgb(255,255,255);"><span>Apache Spark的入门读物</span></h3><p class="graf graf--p graf-after--h3" style="margin-top:8px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>如果您在数据世界中工作，那么您很有可能知道Apache Spark是什么。</span><span>如果你没有那没关系！</span><span>我会告诉你它是什么。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560696998276093.png" title="1560696998276093.png" alt="1_kW0usTU3tShomMP6Ke-DEg.png" class="localImage"></p><p><span>Apache Spark TM。</span></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>火花，由其创建者限定是一个</span><span class="markup--strong markup--p-strong" style="font-weight:700;">快速</span><span>和</span><span class="markup--strong markup--p-strong" style="font-weight:700;">一般</span><span>用于大规模数据处理引擎。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>该</span><span class="markup--strong markup--p-strong" style="font-weight:700;">快速</span><span><span>零件的意思是它的速度比以前的方法与大数据的工作就像经典的MapReduce。</span><span>更快的秘诀是Spark在内存（RAM）上运行，这使得处理速度比在磁盘上快得多。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>在</span><span class="markup--strong markup--p-strong" style="font-weight:700;">一般的</span><span>零件的意思是它可以使用多东西，比如运行的分布式SQL，创建数据管道，提取数据到数据库中，运行机器学习算法，用图表的工作，数据流等等。</span></p><h4 class="graf graf--h4 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:30px 0px 0px;font-size:26px;line-height:1.22;white-space:normal;background-color:rgb(255,255,255);"><span>RDD</span></h4><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697003483375.png" title="1560697003483375.png" alt="1_Ck-GUoBRx7b8rxrgQlNEGQ.png" class="localImage"></p><p><span>来自PySpark-Jeffrey Thompson的图片。</span></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>Apache Spark的主要抽象和开始是弹性分布式数据集（RDD）。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>RDD是可以并行操作的容错的容错集合。</span><span>您可以创建它们并行化驱动程序中的现有集合，或引用外部存储系统中的数据集，例如共享文件系统，HDFS，HBase或提供Hadoop InputFormat的任何数据源。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697007828292.png" title="1560697007828292.png" alt="1_fN_Pj-NmrBFbxNVYexzYoQ.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span class="markup--quote markup--p-quote is-other" style="background-color:transparent;"><span><span>关于Spark的一些非常重要的事情是，所有</span></span><span class="markup--strong markup--p-strong" style="font-weight:700;"><span><span>转换</span></span></span><span><span>（我们将很快定义它）都是懒惰的，即他们不会立即计算结果。</span></span></span><span><span>相反，他们只记得应用于某些基础数据集的转换（例如文件）。</span><span>仅当</span></span><span class="markup--strong markup--p-strong" style="font-weight:700;">操作</span><span><span>需要将结果返回到驱动程序</span><span>时才会计算转换</span><span>。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>默认情况下，每次对其执行操作时，都可以重新计算每个转换后的RDD。</span><span>但是，您也可以</span><span>使用持久化（或缓存）方法在内存中</span></span><em class="markup--em markup--p-em">保留</em><span><span>&nbsp;RDD，在这种情况下，Spark会在群集上保留元素，以便在下次查询时更快地访问。</span><span>还支持在磁盘上保留RDD或在多个节点上复制。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>如果您现在想要了解有关Spark中RDD的转换和操作的更多信息，请查看官方文档：</span></p><p><a rel="nofollow" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>RDD编程指南 - Spark 2.3.0文档</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>Java，Scala和Python中的Spark 2.3.0编程指南</span></span><span><span>spark.apache.org</span></span></a><a rel="nofollow" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*xSZ8hK6ICD439A5w.&quot;);"></a></p><h4 class="graf graf--h4 graf-after--mixtapeEmbed" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:39px 0px 0px;font-size:26px;line-height:1.22;white-space:normal;background-color:rgb(255,255,255);"><span>数据帧</span></h4><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697014440551.png" title="1560697014440551.png" alt="1_t9Cnql3208oRs-ZchANtTg.png" class="localImage"></p><p><span>来自PySpark-Jeffrey Thompson的图片。</span></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>从Spark 2.0.0开始，DataFrame是一个</span><span>组织</span><span>成命名列的</span></span><em class="markup--em markup--p-em">数据集</em><span><span>。</span><span>它在概念上等同于关系数据库中的表或R / Python中的数据框，但在底层具有更丰富的优化。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>我们不会在这里讨论数据集，但是它们被定义为可以</span><span>从JVM对象</span></span><a rel="nofollow" href="https://spark.apache.org/docs/latest/sql-programming-guide.html#creating-datasets" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>构造</span></span></a><span><span>然后使用功能转换进行操作</span><span>的分布式数据集合</span><span>。</span><span>它们仅在Scala和Java中可用（因为它们是键入的）。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>DataFrame可以从多种</span><a rel="nofollow" href="https://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>来源</span></span></a><span><span>构建，</span><span>例如：结构化数据文件，Hive中的表，外部数据库或现有RDD。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697022896049.png" title="1560697022896049.png" alt="1_OY41hGbe4IB9-hHLRPuCHQ.png" class="localImage"></p><p><a rel="nofollow" href="https://aspgems.com/blog/big-data/migrando-de-pandas-spark-dataframes" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://aspgems.com/blog/big-data/migrando-de-pandas-spark-dataframes</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>简而言之，Dataframes API是Spark创建者在框架中轻松使用Data的方式。</span><span>它们与Pandas Dataframes或R Dataframes非常相似，但有几个优点。</span><span>第一个当然是它们可以分布在一个集群中，因此它们可以处理大量数据，第二个是它的优化。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>这是社区采取的非常重要的一步。</span><span>到2014年，使用Spark与Scala或Java的速度要快得多，并且由于性能的原因，整个Spark世界变成了Scala（这是一个很棒的语言顺便说一下）。</span><span>但是使用DF API这不再是一个问题，现在你可以在R，Python，Scala或Java中使用相同的性能。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560696986550145.png" title="1560696986550145.png" alt="1_0qVfl4CXFsuKfTs1hH7sHQ.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>负责此优化的是</span><a rel="nofollow" href="https://databricks.com/blog/2017/08/31/cost-based-optimizer-in-apache-spark-2-2.html" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>Catalyst</span></span></a><span><span>。</span><span>您可以将其视为向导，他会接受您的查询（哦，是的！，您可以在Spark中运行类似SQL的查询，针对DF运行它们，并且它们也将并行化）以及您的操作并创建优化的计划用于分配计算。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560696992742528.png" title="1560696992742528.png" alt="1_81ZOMxCci-tM2b-HNUX6Ww.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>这个过程并不那么简单，但作为程序员你甚至都不会注意到它。</span><span>刚才它一直在帮助你。</span></span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;white-space:normal;background-color:rgb(255,255,255);"><span>深度学习和Apache Spark</span></h3><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697002666584.gif" title="1560697002666584.gif" alt="1_R-ItxBW2SWarITBKe7HZuA.gif" class="localImage"></p><p><a rel="nofollow" href="https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>如果您想了解有关深度学习的更多信息，请在继续之前阅读这些帖子：</span></p><p><a rel="nofollow" href="https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>深度学习的“奇怪”介绍有关深度学习</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span><span>的精彩介绍，课程和博客文章。</span><span>但这是一种不同的介绍。</span></span></span><span><span>towardsdatascience.com</span></span></a><a rel="nofollow" href="https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/1*oJgUOQB7LioM_0FiCrKqAw.jpeg&quot;);"></a></p><p><a rel="nofollow" href="https://towardsdatascience.com/my-journey-into-deep-learning-c66e6ef2a317" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://towardsdatascience.com/my-journey-into-deep-learning-c66e6ef2a317" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>我的深度学习之旅</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span><span>在这篇文章中，我将分享我如何研究深度学习并用它来解决数据科学问题。</span><span>这是一个...</span></span></span><span><span>朝向dasascience.com</span></span></a><a rel="nofollow" href="https://towardsdatascience.com/my-journey-into-deep-learning-c66e6ef2a317" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/1*lGnhxVhNcjXOzQoQlTL06Q.jpeg&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>为什么要在Apache Spark上进行深度学习？</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>这是我在开始研究这个主题之前问过自己的问题。</span><span>答案分为两部分：</span></span></p><ol class="postList list-paddingleft-2" style="list-style-type:none;"><li><p><span><span>Apache Spark是一个令人惊叹的框架，用于以简单和声明的方式在集群中分发计算。</span><span>正在成为跨行业的标准，因此将深度学习的惊人进步添加到其中会很棒。</span></span></p></li><li><p><span><span>深度学习的某些部分计算量很大，非常沉重！</span><span>分发这些进程可能是解决其他问题的方法，而Apache Spark是我认为分发它们的最简单方法。</span></span></p></li></ol><p class="graf graf--p graf-after--li" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>有几种方法可以使用Apache Spark进行深度学习，我之前讨论过它们，我在这里再次列出它们（并非详尽无遗）：</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>1.&nbsp;</span><a rel="nofollow" href="http://maxpumperla.github.io/elephas/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>Elephas</span></span></a><span>：带Keras和PySpark的分布式DL：</span></p><p><a rel="nofollow" href="https://github.com/maxpumperla/elephas" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/maxpumperla/elephas" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>maxpumperla / elephas</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>elephas - 使用</span></span><span><span>Keras</span><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>和Spark</span></span><span>github.com进行</span><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>分布式深度学习</span></span></span></a><a rel="nofollow" href="https://github.com/maxpumperla/elephas" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*WGqtvKDQj3xBNb4m.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><a rel="nofollow" href="https://www.linkedin.com/company/1288/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span class="markup--strong markup--p-strong" style="font-weight:700;"><span><span>2.雅虎！</span><span>公司</span></span></span></a><span>：TensorFlowOnSpark：</span></p><p><a rel="nofollow" href="https://github.com/yahoo/TensorFlowOnSpark" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/yahoo/TensorFlowOnSpark" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>yahoo / TensorFlowOnSpark</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>TensorFlowOnSpark将TensorFlow程序带入Apache Spark集群</span></span><span><span>github.com</span></span></a><a rel="nofollow" href="https://github.com/yahoo/TensorFlowOnSpark" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*TUjDfp-jjqUFQkj2.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><a rel="nofollow" href="https://www.linkedin.com/company/157302/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span class="markup--strong markup--p-strong" style="font-weight:700;"><span><span>3. CERN</span></span></span></a><span>分布式Keras（Keras + Spark）：</span></p><p><a rel="nofollow" href="https://github.com/cerndb/dist-keras" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/cerndb/dist-keras" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>cerndb / dist-keras</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>dist-keras - 分布式深度学习，重点是分布式训练，使用Keras和Apache Spark。</span></span><span><span>github.com</span></span></a><a rel="nofollow" href="https://github.com/cerndb/dist-keras" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*im4uzRe9jmVa_d_8.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><a rel="nofollow" href="https://www.linkedin.com/company/2531735/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span class="markup--strong markup--p-strong" style="font-weight:700;"><span><span>4. Qubole</span></span></span></a><span><span>（教程</span><a rel="nofollow" href="https://www.linkedin.com/company/2531735/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span class="markup--strong markup--p-strong" style="font-weight:700;"><span>&nbsp;Keras</span></span></a><span>&nbsp;+ Spark）：</span></span></p><p><a rel="nofollow" href="https://www.qubole.com/blog/distributed-deep-learning-keras-apache-spark/" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.qubole.com/blog/distributed-deep-learning-keras-apache-spark/" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span><span>Apache Spark上使用Keras进行分布式深度学习&nbsp;</span><span>Qubole</span></span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span><span>深度学习已被证明可以在不同的领域中生成高效的机器学习模型。</span><span>一些...</span></span></span><span><span>www.qubole.com</span></span></a><a rel="nofollow" href="https://www.qubole.com/blog/distributed-deep-learning-keras-apache-spark/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*3D7jaXrXeujvOCxd.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><a rel="nofollow" href="https://www.linkedin.com/company/1053/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span class="markup--strong markup--p-strong" style="font-weight:700;"><span><span>5.英特尔公司</span></span></span></a><span>：BigDL（Apache Spark的分布式深度学习库）</span></p><p><a rel="nofollow" href="https://github.com/intel-analytics/BigDL" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/intel-analytics/BigDL" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>intel-analytics / BigDL</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>BigDL：Apache Spark</span></span><span><span>github.com的</span><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>分布式深度学习库</span></span></span></a><a rel="nofollow" href="https://github.com/intel-analytics/BigDL" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*3zaYuDbPbUuPay0U.&quot;);"></a></p><h3 class="graf graf--h3 graf-after--mixtapeEmbed" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:53px 0px 0px;font-size:34px;line-height:1.15;white-space:normal;background-color:rgb(255,255,255);"><span>深度学习管道</span></h3><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697052927892.png" title="1560697052927892.png" alt="1_6gBbuSw5qH34uI7GF4p97A.png" class="localImage"></p><p><span>Databricks</span></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>但我将重点关注这些文章的是</span><span class="markup--strong markup--p-strong" style="font-weight:700;">深度学习管道。</span></p><p><a rel="nofollow" href="https://github.com/databricks/spark-deep-learning" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/databricks/spark-deep-learning" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>databricks / spark-deep-learning</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>spark-deep-learning - Apache Spark</span></span><span><span>github.com的</span><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>深度学习管道</span></span></span></a><a rel="nofollow" href="https://github.com/databricks/spark-deep-learning" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*aPa5xM_Mk8JqmTZy.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>Deep Learning Pipelines是由Databricks创建的一个开源库，它使用Apache Spark为Python中的可扩展深度学习提供高级API。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>这是一项非常棒的工作，不久就会被合并到官方API中，因此值得一看。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>与我之前列出的库相比，该库的一些优点是：</span></p><ul class="postList list-paddingleft-2" style="list-style-type:none;"><li><p><span>本着Spark和</span><a rel="nofollow" href="https://spark.apache.org/mllib/" class="markup--anchor markup--li-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>Spark MLlib</span></span></a><span><span>的精神</span><span>，它提供了易于使用的API，可以在极少数代码行中实现深度学习。</span></span></p></li><li><p><span>它着重于易用性和集成，而不会牺牲性能。</span></p></li><li><p><span>它由Apache Spark的创建者（也是主要贡献者）构建，因此它更有可能被合并为官方API而不是其他人。</span></p></li><li><p><span>它是用Python编写的，因此它将与所有着名的库集成，现在它使用TensorFlow和Keras的强大功能，这是目前DL的两个主要库。</span></p></li></ul><p class="graf graf--p graf-after--li" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>在下一篇文章中，我将完全关注DL管道库以及如何从头开始使用它。</span><span>您将看到的一件事是简单管道上的转移学习，如何使用预先训练的模型处理“少量”数据并能够预测事物，如何通过深入了解公司中的每个人您在SQL中创建的学习模型等等。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>此外，我还将在Deep Cognition Platform中创建一个使用此库在笔记本中工作的环境，以便您可以测试所有内容。</span><span>如果您没有开始，请继续创建一个免费帐户：</span></span></p><p><a rel="nofollow" href="http://deepcognition.ai/" class="markup--anchor markup--mixtapeEmbed-anchor" title="http://deepcognition.ai" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>DeepCognition - 今天成为AI支持的组织</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span><span>，无需编码即可设计，训练和部署深度学习模型。</span><span>Deep Learning Studio简化并加速了...</span></span></span><span><span>deepcognition.ai</span></span></a><a rel="nofollow" href="http://deepcognition.ai/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*y1NVCXVG3v1YpFIp.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>哦！！</span><span>顺便说一句，如果你现在想要更多关于Python数据科学中的管道，请查看Matthew Mayo撰写的这些精彩文章：</span></span></p><p><a rel="nofollow" href="https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>使用Scikit-learn管道管理机器学习工作流程第1部分：温和的介绍</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span><span>您是否熟悉Scikit-learn Pipelines？</span><span>它们是一个非常简单但非常有用的管理机器的工具...</span></span></span><span><span>www.kdnuggets.com</span></span></a><a rel="nofollow" href="https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*pWuZTuqse8jcBXsa.&quot;);"></a></p><p><a rel="nofollow" href="https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>使用Scikit-learn管道管理机器学习工作流程第2部分：集成网格搜索</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>在上一篇文章中，我们将Scikit-learn管道作为简化机器学习工作流程的方法。</span></span><span><span>www.kdnuggets.com</span></span></a><a rel="nofollow" href="https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*-ePnKmoD5EcC8J8L.&quot;);"></a></p><p><a rel="nofollow" href="https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-3.html" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-3.html" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>使用Scikit-learn Pipelines管理机器学习工作流程第3部分：多个模型，管道......</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>首先，我知道我承诺我们将在上</span></span><span><span>一篇</span><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>文章中过去玩具数据集，但为了进行比较，我们将...</span></span><span>www.kdnuggets.com</span></span></a><a rel="nofollow" href="https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-3.html" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*gSrJWP2pmnBY--j6.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>有关Spark的管道简介请查看：</span></p><p><a rel="nofollow" href="https://spark.apache.org/docs/latest/ml-pipeline.html" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://spark.apache.org/docs/latest/ml-pipeline.html" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>ML Pipelines - Spark 2.3.0文档</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span><span>Estimator提取学习算法或任何适合或训练数据的算法的概念。</span><span>技术上......</span></span></span><span><span>spark.apache.org</span></span></a><a rel="nofollow" href="https://spark.apache.org/docs/latest/ml-pipeline.html" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*NGiahkQkJf6PJxa3.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed graf--trailing" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>再见 ：）</span></p><p class="graf graf--p graf-after--mixtapeEmbed graf--trailing" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>原文:<a rel="nofollow" href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-2-2a2938a36d35">https://towardsdatascience.com/deep-learning-with-apache-spark-part-2-2a2938a36d35</a></span></p><h1 class="graf graf--h3 graf--leading graf--title" style="font-size:42px;margin:0px;font-family:'medium-content-title-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-weight:400;line-height:1.25;white-space:normal;background-color:rgb(255,255,255);padding-top:16px;"><span>使用Apache Spark进行深度学习 - 第2部分</span></h1><h2 class="graf graf--h4 graf-after--h3 graf--subtitle" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;font-weight:400;margin:5px 0px 22px;font-size:28px;line-height:1.22;white-space:normal;background-color:rgb(255,255,255);"><span><span>第二部分是关于如何使用Apache Spark进行分布式深度学习的完整讨论。</span><span>我将完全专注于DL管道库以及如何从头开始使用它。</span><span>您将看到的一件事是简单管道上的转移学习，如何使用预先训练的模型处理“少量”数据并能够预测事物等等。</span></span></h2><section><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>大家好，欢迎回来学习:)。</span><span>在本文中，我将继续讨论使用Apache Spark进行深度学习。</span><span>你可以在</span></span><a rel="nofollow" href="https://towardsdatascience.com/deep-learning-with-apache-spark-part-1-6d397c16abd" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>这里</span></span></a><span><span>看到第一部分</span><span>。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>在这一部分中，我将完全关注DL管道库以及如何从头开始使用它。</span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;"><span>Apache Spark时间线</span></h3><p class="graf graf--p graf-after--h3" style="margin-top:8px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>Apache Spark的持续改进引导我们讨论如何使用它进行深度学习。</span><span>我创建了一个详细的Apache Spark开发时间表，直到现在才看到我们如何到达这里。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697209830515.png" title="1560697209830515.png" alt="1_dtLoj7pHnbT_rVmv5Y6yFA.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>很快，我将创建一篇包含此时间线描述的文章，但如果您认为有什么遗漏请告诉我:)</span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;"><span>深度学习管道</span></h3><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697214418597.png" title="1560697214418597.png" alt="1_6gBbuSw5qH34uI7GF4p97A.png" class="localImage"></p><p><span>Databricks</span></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>Deep Learning Pipelines是由Databricks创建的一个开源库，它使用Apache Spark为Python中的可扩展深度学习提供高级API。</span></p><p><a rel="nofollow" href="https://github.com/databricks/spark-deep-learning" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/databricks/spark-deep-learning" style="display:table-cell;vertical-align:middle;padding:20px;"><span class="markup--strong markup--mixtapeEmbed-strong" style="letter-spacing:0px;font-size:18px;line-height:1.3;display:block;margin-bottom:-8px;"><span>databricks / spark-deep-learning</span></span><br><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>spark-deep-learning - Apache Spark</span></span><span><span>github.com的</span><span class="markup--em markup--mixtapeEmbed-em" style="font-size:16px;display:block;margin-top:-1px;margin-bottom:10px;overflow:hidden;"><span>深度学习管道</span></span></span></a><a rel="nofollow" href="https://github.com/databricks/spark-deep-learning" class="js-mixtapeImage mixtapeImage u-ignoreBlock" style="background-color:transparent;display:table-cell;vertical-align:middle;width:160px;height:160px;background-repeat:no-repeat;background-position:center;background-image:url(&quot;https://cdn-images-1.medium.com/fit/c/160/160/0*aPa5xM_Mk8JqmTZy.&quot;);"></a></p><p class="graf graf--p graf-after--mixtapeEmbed" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>这是一项非常棒的工作，不久就会被合并到官方API中，因此值得一看。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>与使用DL加入Spark的库相比，该库的一些优点是：</span></p><ul class="postList list-paddingleft-2" style="list-style-type:none;"><li><p><span>本着Spark和</span><a rel="nofollow" href="https://spark.apache.org/mllib/" class="markup--anchor markup--li-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>Spark MLlib</span></span></a><span><span>的精神</span><span>，它提供了易于使用的API，可以在极少数代码行中实现深度学习。</span></span></p></li><li><p><span>它着重于易用性和集成，而不会牺牲性能。</span></p></li><li><p><span>它由Apache Spark的创建者（也是主要贡献者）构建，因此它更有可能被合并为官方API而不是其他人。</span></p></li><li><p><span>它是用Python编写的，因此它将与所有着名的库集成，现在它使用TensorFlow和Keras的强大功能，这是目前DL的两个主要库。</span></p></li></ul><p class="graf graf--p graf-after--li" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>深度学习管道建立在Apache Spark的</span><a rel="nofollow" href="https://spark.apache.org/docs/latest/ml-pipeline.html" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>ML</span></span></a><span><span>&nbsp;Pipelines之上，</span><span>用于培训，Spark DataFrames和SQL用于部署模型。</span><span>它包含用于深度学习的常见方面的高级API，因此可以通过几行代码高效完成：</span></span></p><ul class="postList list-paddingleft-2" style="list-style-type:none;"><li><p><span>图像加载</span></p></li><li><p><span>将预先训练的模型应用于Spark ML管道中的变换器</span></p></li><li><p><span>转学习</span></p></li><li><p><span>大规模应用深度学习模型</span></p></li><li><p><span>分布式超参数调整</span><span class="markup--strong markup--li-strong" style="font-weight:700;">（下一部分）</span></p></li><li><p><span>在DataFrames和SQL中部署模型</span></p></li></ul><p class="graf graf--p graf-after--li" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>我将描述每个吨</span><span class="markup--quote markup--p-quote is-other" style="background-color:transparent;"><span><span>ħ</span></span></span><span><span>与实施例详细ESE特征。</span><span>这些例子来自</span><span>Databricks&nbsp;</span><span>的官方</span></span><a rel="nofollow" href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/5669198905533692/3647723071348946/3983381308530741/latest.html" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>笔记本</span></span></a><span>。</span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;"><span>深度认知的Apache Spark</span></h3><p class="graf graf--p graf-after--h3" style="margin-top:8px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>要运行和测试本文中的代码，您需要在</span><a rel="nofollow" href="http://deepcognition.ai/register/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>Deep Cognition中</span></span></a><span><span>创建一个帐户</span><span>。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>非常简单，然后您就可以访问他们的所有功能。</span><span>当您登录时，您应该看到：</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697219872754.png" title="1560697219872754.png" alt="1_8ijqj85Tjscv9xpXjHfEFA.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>现在只需单击左侧部分，即Notebook按钮：</span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697225634809.png" title="1560697225634809.png" alt="1_mnMlcYuO2U-KzRvYSuj-Cw.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>你将在Jupyter笔记本上安装所有已安装的软件包:)。</span><span>哦!&nbsp;</span><span>这里有一个注意事项：Spark笔记本电脑（DLS SPARK）即将推出的功能将在下个月的某个时候发布，并告知它仍处于私人测试状态（仅适用于此帖）。</span></span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697230147420.png" title="1560697230147420.png" alt="1_cbQSGKgPDBNoBfGdDJqESg.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>您可以在此处下载完整的Notebook以查看所有代码：</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><a rel="nofollow" href="https://github.com/FavioVazquez/deep-learning-pyspark" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://github.com/FavioVazquez/deep-learning-pyspark</span></span></a></p><h4 class="graf graf--h4 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:30px 0px 0px;font-size:26px;line-height:1.22;"><span>图片加载</span></h4><p class="graf graf--p graf-after--h4" style="margin-top:6px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>在图像上应用深度学习的第一步是加载图像的能力。</span><span>深度学习管道包括实用程序功能，可以将数百万个图像加载到DataFrame中，并以分布式方式自动解码，允许大规模操作。</span><span>新版本的spark（2.3.0）也具备此功能，但我们将使用sparkdl库。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>我们将使用由TensorFlow策划的创作公共许可花卉照片存档来测试它。</span><span>要获取花卉照片集，请从笔记本中运行这些命令（我们还将创建一个示例文件夹）：</span></span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/33350294e31213ff761bf2ff51e25c4a" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/33350294e31213ff761bf2ff51e25c4a</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>让我们从郁金香和雏菊文件夹中复制一些照片，以创建一小部分照片样本。</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/8ce726807f6074c05a779ee4e5e3a4d0" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/8ce726807f6074c05a779ee4e5e3a4d0</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>要在笔记本上查看这些图像，您可以运行以下命令：</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/efaa901f85b51c77d520595136a2cb52" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/efaa901f85b51c77d520595136a2cb52</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>你应该看到这个</span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697236721261.png" title="1560697236721261.png" alt="1_qVp67i3d_qUIWwzE5PNyCQ.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>现在让我们使用Spark将这些图像作为DataFrame加载。</span><span>该方法</span></span><code class="markup--code markup--p-code" style="font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;padding:3px 4px;margin:0px 2px;">spark.readImage</code><span><span>允许您以常见格式（jpg，png等）从HDFS存储读取图像到DataFrame。</span><span>每个图像都以imageSchema格式存储为一行。</span><span>递归选项允许您从子文件夹中读取图像，例如正面和负面标记的样本。</span><span>sampleRatio参数允许您在使用完整数据训练模型之前尝试较小的图像样本。</span></span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/85266329b7ef31411600f33c3b9eee1e" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/85266329b7ef31411600f33c3b9eee1e</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>如果我们看看这个数据帧，我们会看到它创建了一个列，称为“图像”。</span></p><pre class="graf graf--pre graf-after--p" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:43px;margin-bottom:0px;padding:20px;white-space:pre-wrap;">image_df.show（）</pre><pre class="graf graf--pre graf-after--pre" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:0px;margin-bottom:0px;padding:4px 20px 20px;white-space:pre-wrap;"><span>+ -------------------- + </span><br><span><span>| </span><span>图片| </span></span><br><span>+ -------------------- + </span><br><span>| [file：/ Users / favi ... | </span><br><span>| [文件：/用户/ FAVI ... | </span><br><span>| [文件：/用户/ FAVI ... | </span><br><span>+ -------------------- +</span></pre><p class="graf graf--p graf-after--pre" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>image列包含一个字符串列，其中包含一个带有schema == ImageSchema的图像结构。</span></p><h4 class="graf graf--h4 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:30px 0px 0px;font-size:26px;line-height:1.22;"><span>转学习</span></h4><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697205744784.png" title="1560697205744784.png" alt="1_6eDLqIz2sOtdI-6X87Ervg.png" class="localImage"></p><p><span>Databricks</span></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>深度学习管道提供了用于</span><span>对图像</span><span>执行</span></span><a rel="nofollow" href="https://en.wikipedia.org/wiki/Transfer_learning" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>传输学习的</span></span></a><span><span>实用程序</span><span>，这是开始使用深度学习的最快（代码和运行时）方法之一。</span><span>使用深度学习管道，只需几行代码就可以完成。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>深度学习管道能够快速传输带的概念学习</span><em class="markup--em markup--p-em">Featurizer</em><span><span>。</span><span>以下示例将Spark中的InceptionV3模型和逻辑回归组合在一起，以使InceptionV3适应我们的特定域。</span></span><span class="markup--strong markup--p-strong" style="font-weight:700;">DeepImageFeaturizer自动剥离预先训练的神经网络的最后一层，并使用所有先前层的输出作为逻辑回归算法的特征</span><span><span>。</span><span>由于逻辑回归是一种简单而快速的算法，因此这种转移学习训练可以使用比从头开始训练深度学习模型通常所需的图像少得多的图像来快速收敛。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>首先，我们需要为转移学习创建培训和测试DataFrame。</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/84b0201f2ec0cbfc64fa3736bc7a76b5" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/84b0201f2ec0cbfc64fa3736bc7a76b5</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>现在让我们训练模型</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/96e13301b6286eb7b52f34faedce4c24" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/96e13301b6286eb7b52f34faedce4c24</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>让我们看看该模型的表现如何：</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/27fa7de28011d41b192d723a185a9b87" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/27fa7de28011d41b192d723a185a9b87</span></span></a></p><pre class="graf graf--pre graf-after--figure" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:52px;margin-bottom:0px;padding:20px;white-space:pre-wrap;">测试集精度=&nbsp;0.9753086419753086</pre><p class="graf graf--p graf-after--pre" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>一个例子并没有那么糟糕，根本没有调整！</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>我们可以看看我们犯错误的地方：</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/dcd72fe4f0f4204736d46ba57112cb97" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/dcd72fe4f0f4204736d46ba57112cb97</span></span></a></p><h4 class="graf graf--h4 graf-after--figure" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:39px 0px 0px;font-size:26px;line-height:1.22;"><span>大规模应用深度学习模型</span></h4><p class="graf graf--p graf-after--h4" style="margin-top:6px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>Deep Learning Pipelines支持使用Spark以分布式方式运行预训练模型，可在批处理和</span><a rel="nofollow" href="https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>流数据处理中使用</span></span></a><span>。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>它包含一些最流行的模型，使用户可以开始使用深度学习，而无需昂贵的培训模型步骤。</span><span>当然，模型的预测与Spark带来的所有好处并行完成。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>除了使用内置模型，用户还可以</span><span>在Spark预测管道中</span><span>插入</span></span><a rel="nofollow" href="https://keras.io/models/about-keras-models/" class="markup--anchor markup--p-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>Keras模型</span></span></a><span><span>和TensorFlow Graphs。</span><span>这将单节点工具上的任何单节点模型转换为可以以分布式方式应用于大量数据的模型。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>以下代码使用InceptionV3创建Spark预测管道，InceptionV3是用于图像分类的最先进的卷积神经网络（CNN）模型，并预测我们刚刚加载的图像中的对象。</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/b6e4ab8787f4bd4a7186d858a86c3521" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/b6e4ab8787f4bd4a7186d858a86c3521</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>我们来看一下预测数据帧：</span></p><pre class="graf graf--pre graf-after--p" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:43px;margin-bottom:0px;padding:20px;white-space:pre-wrap;">predictions_df.select（&nbsp;“predicted_labels”）。显示（截断=假，N&nbsp;=&nbsp;3）</pre><pre class="graf graf--pre graf-after--pre" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:0px;margin-bottom:0px;padding:4px 20px 20px;white-space:pre-wrap;"><span>+ ---------------- + </span><br><span><span>| predict_labels | </span><span>| </span><span>| </span></span><br><span>+ ---------------- + </span><br><span>| [[n03930313，picket_fence，0.1424783]，</span><span class="markup--strong markup--pre-strong" style="font-weight:700;">[n11939491，daisy，0.10951301]</span><span>，[n03991062，pot，0.04505]，[n02206856，bee，0.03734662 ]，[n02280649，cabbage_butterfly，0.019011213]，[n13133613，ear，0.017185668]，[n02219486，ant，0.014198389]，[n02281406，sulphur_butterfly，0.013113698]，[n12620546，hip，0.012272579]，[n03457902，greenhouse，0.011370744]] |</span></pre><pre class="graf graf--pre graf-after--pre" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:0px;margin-bottom:0px;padding:4px 20px 20px;white-space:pre-wrap;">|&nbsp;[[n11939491，daisy，0.9532104]，[n02219486，ant，6.175268E-4]，[n02206856，bee，5.1203516E-4]，[n02190166，fly，4.0093894E-4]，[n02165456，ladybug，3.70687E-&nbsp;4]，[n02281406，sulphur_butterfly，3.0587992E-4]，[n02112018，Pomeranian，2.9011074E-4]，[n01795545，black_grouse，2.5667972E-4]，[n02177972，weevil，2.4875381E-4]，[n07745940，草莓，2.3729511E-4]]&nbsp;|</pre><pre class="graf graf--pre graf-after--pre" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:0px;margin-bottom:0px;padding:4px 20px 20px;white-space:pre-wrap;"><span>| </span><span class="markup--strong markup--pre-strong" style="font-weight:700;">[[n11939491，daisy，0.89181453]</span><span>，[n02219486，ant，0.0012404523]，[n02206856，bee，8.13047E-4]，[n02190166，fly，6.03804E-4]，[n02165456，ladybug，6.005444E-4]， [n02281406，sulphur_butterfly，5.32096E-4]，[n04599235，wool，4.6653638E-4]，[n02112018，Pomeranian，4.625338E-4]，[n07930864，cup，4.400617E-4]，[n02177972，weevil，4.2434104 E-4]] | </span><br><span>+ ---------------- + </span><br><span>仅显示前3行</span></pre><p class="graf graf--p graf-after--pre" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>请注意，该</span><code class="markup--code markup--p-code" style="font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;padding:3px 4px;margin:0px 2px;">predicted_labels</code><span>列显示“菊花”作为使用此基本模型的所有样本花的高概率类，</span><span class="markup--strong markup--p-strong" style="font-weight:700;">由于某种原因，郁金香更接近栅栏而不是花（可能是因为照片的背景）</span><span>。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>然而，从概率值的差异可以看出，神经网络具有识别两种花类型的信息。</span><span>因此，我们上面的转移学习示例能够从基础模型开始正确地学习雏菊和郁金香之间的差异。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>让我们看看我们的模型如何识别花的类型：</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/271c069453b5917d85aeec0001d54624" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/271c069453b5917d85aeec0001d54624</span></span></a></p><h4 class="graf graf--h4 graf-after--figure" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:39px 0px 0px;font-size:26px;line-height:1.22;"><span>对于Keras用户</span></h4><p class="graf graf--p graf-after--h4" style="margin-top:6px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>要使用Spark以分布式方式应用Keras模型，请使用</span><code class="markup--code markup--p-code" style="font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;padding:3px 4px;margin:0px 2px;"><a rel="nofollow" href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6026450283250196/3874201704285756/7409402632610251/link_here" class="markup--anchor markup--p-anchor" style="background:0px 0px;">KerasImageFileTransformer</a></code><span><span>TensorFlow支持的Keras模型。</span><span>它</span></span></p><ul class="postList list-paddingleft-2" style="list-style-type:none;"><li><p><span>通过将用户指定的图像加载和处理函数应用于包含一列图像URI的输入DataFrame，在内部创建包含一列图像的DataFrame</span></p></li><li><p><span>从给定的模型文件路径加载Keras模型</span></p></li><li><p><span>将模型应用于图像DataFrame</span></p></li></ul><p class="graf graf--p graf-after--li" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>要使用变压器，我们首先需要将Keras模型存储为文件。</span><span>对于这款笔记本，我们只需保存Keras内置的InceptionV3模型而不是训练模型。</span></span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/bc7d280cd98a7112cb96f13cded20259" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/bc7d280cd98a7112cb96f13cded20259</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>现在我们将创建一个Keras变换器，但首先我们将预处理图像以使用它</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/b1a43d8611e1fd2db9a3c61742156e97" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/b1a43d8611e1fd2db9a3c61742156e97</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>我们现在将读取图像并将它们加载到Spark Dataframe中，然后使用我们的变换器将模型应用到图像中：</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/531c2852f936e4a2cbbe2f4afbad47d5" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/531c2852f936e4a2cbbe2f4afbad47d5</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>如果我们看一下带有预测的数据帧，我们会看到很多信息，而这只是InceptionV3模型中每个类的概率。</span></p><h4 class="graf graf--h4 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:30px 0px 0px;font-size:26px;line-height:1.22;"><span>使用一般张量</span></h4><p class="graf graf--p graf-after--h4" style="margin-top:6px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>深度学习管道还提供了应用具有张量输入（最多2维）的模型的方法，用流行的深度学习库编写：</span></p><ul class="postList list-paddingleft-2" style="list-style-type:none;"><li><p><span>TensorFlow图</span></p></li><li><p><span>Keras型号</span></p></li></ul><p class="graf graf--p graf-after--li" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>在本文中，我们将只关注Keras模型。</span><span>将</span></span><code class="markup--code markup--p-code" style="font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;padding:3px 4px;margin:0px 2px;">KerasTransformer</code><span><span>TensorFlow支持的Keras模型应用于最多2维的张量输入。</span><span>它从给定的模型文件路径加载Keras模型，并将模型应用于数组列（其中数组对应于Tensor），输出一列数组。</span></span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/bab4fbf9c39aade9b92dbbea95127cec" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/bab4fbf9c39aade9b92dbbea95127cec</span></span></a></p><pre class="graf graf--pre graf-after--figure" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:52px;margin-bottom:0px;padding:20px;white-space:pre-wrap;">final_df.show（）</pre><pre class="graf graf--pre graf-after--pre" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:0px;margin-bottom:0px;padding:4px 20px 20px;white-space:pre-wrap;"><span>+ ------------- + -------------------- + </span><br><span><span>| </span><span>预测| </span><span>功能| </span></span><br><span>+ ------------- + -------------------- + </span><br><span><span>| </span><span>[0.86104786] | [-0.76344526,0.2 ... | </span></span><br><span><span>| </span><span>[0.21693115] | [0.41084298,0.93 ... | </span></span><br><span>| [0.057743043] | [0.062970825,0.3 ... | </span><br><span><span>| </span><span>[0.43409333] | [-0.43408343，-1 .... | </span></span><br><span><span>| </span><span>[0.43690935] | [-0.89413625,0.8 ... | </span></span><br><span><span>| </span><span>[0.49984664] | [-0.82052463，-0 .... | </span></span><br><span><span>| </span><span>[0.6204273] | [-0.5075533,0.54 ... | </span></span><br><span><span>| </span><span>[0.2285336] | [0.016106872，-0 .... | </span></span><br><span><span>| </span><span>[0.37478408] | [-1.6756374,0.84 ... | </span></span><br><span><span>| </span><span>[0.2997861] | [-0.34952268,1.2 ... | </span></span><br><span><span>| </span><span>[0.3885377] | [0.1639214，-0.22 ... | </span></span><br><span><span>| </span><span>[0.5006814] | [0.91551965，-0.3 ... | </span></span><br><span><span>| </span><span>[0.20518135] | [-1.2620118，-0.4 ... | </span></span><br><span><span>| </span><span>[0.18882117] | [-0.14812712,0.8 ... |</span></span><br><span><span>| </span><span>[0.49993372] | [1.4617485，-0.33 ... | </span></span><br><span><span>| </span><span>[0.42390883] | [-0.877813,0.603 ... | </span></span><br><span><span>| </span><span>[0.5232896] | [-0.031451378，-1 ... | </span></span><br><span><span>| </span><span>[0.45858437] | [0.9310042，-1.77 ... | </span></span><br><span><span>| </span><span>[0.49794272] | [-0.37061003，-1 .... | </span></span><br><span><span>| </span><span>[0.2543479] | [0.41954428,1.88 ... | </span></span><br><span>+ ------------- + -------------------- + </span><br><span>仅显示前20行</span></pre><h4 class="graf graf--h4 graf-after--pre" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.012em;margin:39px 0px 0px;font-size:26px;line-height:1.22;"><span>在SQL中部署模型</span></h4><p class="graf graf--p graf-after--h4" style="margin-top:6px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>生成模型的一种方法是将其部署为Spark SQL用户定义函数，该函数允许任何知道SQL的人使用它。</span><span>深度学习管道提供了采用深度学习模型并</span></span><em class="markup--em markup--p-em">注册</em><span><span>Spark SQL用户定义函数（UDF）的机制。</span><span>特别是，Deep Learning Pipelines 0.2.0增加了对从处理图像数据的Keras模型创建SQL UDF的支持。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>生成的UDF采用一列（格式化为图像结构“SpImage”）并生成给定Keras模型的输出;&nbsp;</span><span>例如，对于Inception V3，它会在ImageNet对象类别上生成实值分数向量。</span></span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/3a36edf25a289f4ee31cff1bf3857467" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/3a36edf25a289f4ee31cff1bf3857467</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>在处理图像的Keras工作流程中，在将模型应用于图像之前，通常会有预处理步骤。</span><span>如果我们的工作流程需要预处理，我们可以选择为UDF注册提供预处理功能。</span><span>预处理器应该接收文件路径并返回一个图像数组;&nbsp;</span><span>下面是一个简单的例子。</span></span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/a02094a5848ab1f7e42ce52820a09fbe" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/a02094a5848ab1f7e42ce52820a09fbe</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>注册UDF后，可以在SQL查询中使用它：</span></p><p><a rel="nofollow" href="https://gist.github.com/FavioVazquez/af566a98d19952eb0b61938c4752f7dc" class="markup--anchor markup--figure-anchor" style="background-color:transparent;background-repeat:repeat-x;background-position:0px;"><span><span>https://gist.github.com/FavioVazquez/af566a98d19952eb0b61938c4752f7dc</span></span></a></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span><span>这非常强大。</span><span>一旦数据科学家构建了所需的模型，深度学习管道就可以很容易地将其作为SQL中的函数公开，因此组织中的任何人都可以使用它 - 数据工程师，数据科学家，业务分析师，任何人。</span></span></p><pre class="graf graf--pre graf-after--p" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:43px;margin-bottom:0px;padding:20px;white-space:pre-wrap;">sparkdl.registerKerasUDF("awesome_dl_model",&nbsp;"/mymodels/businessmodel.h5")</pre><p class="graf graf--p graf-after--pre" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>接下来，组织中的任何用户都可以在SQL中应用预测：</span></p><pre class="graf graf--pre graf-after--p graf--trailing" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;font-size:16px;margin-top:43px;margin-bottom:0px;padding:20px;white-space:pre-wrap;"><code class="markup--code markup--pre-code" style="font-family:inherit;font-size:1em;">SELECT image, awesome_dl_model(image) label FROM images <br>WHERE contains(label, “Product”)</code></pre></section><p><br></p><section><hr><p class="graf graf--p graf--leading" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>在下一部分中，我将讨论使用Spark的分布式超参数调优，并将尝试新的模型和示例:)。</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><span>如果您想与我联系，请务必在Twitter上关注我</span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;">原文:<a rel="nofollow" href="https://medium.com/@lavishj77/apache-spark-fundamentals-part-1-918d2a404e86">https://medium.com/@lavishj77/apache-spark-fundamentals-part-1-918d2a404e86</a></p><h1 class="graf graf--h3 graf--leading graf--title" style="font-size:42px;margin:0px;font-family:'medium-content-title-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-weight:400;line-height:1.25;white-space:normal;background-color:rgb(255,255,255);padding-top:16px;"><span>Apache Spark基础知识（第1部分）</span></h1><p class="graf graf--p graf-after--h3" style="margin-top:8px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>数据正在当今世界广泛生产，并且将来会更快地生成。</span><span>世界上生产的总数据的90％仅在过去两年内生成，估计到2020年世界总数据将达到45 ZB，并且如果我们尝试将其存储在蓝色中，那么每天生成的数据就足够了光盘（每个50 GB）并将这些光盘一个堆叠在另一个之上，然后该堆叠的高度将等于四个堆叠在另一个之上的埃菲尔铁塔。</span><span>使用传统的关系SQL数据库无法存储和处理大量的结构化，非结构化或半结构化数据。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>Apache Spark是一个开源</span><span class="markup--strong markup--p-strong" style="font-weight:700;">&nbsp;</span><span>并行处理</span><span class="markup--strong markup--p-strong" style="font-weight:700;">&nbsp;</span><span><span>框架，用于跨群集计算机存储和处理大数据。</span><span>Spark可以比Hadoop更快地执行计算，而Hadoop和Spark可以有效地一起使用。</span><span>Spark是用Scala编写的，Scala被认为是与Spark Core引擎交互的主要语言。</span><span>Spark还提供Java，Python和R编程语言的API。</span></span><span class="markup--strong markup--p-strong" style="font-weight:700;">这篇博客中的代码将在PySpark中，它是Spark的python API</span><span><span>。</span><span>Spark可以在独立的集群模式下运行，它可以运行在不同类型的集群上，例如Hadoop YARN集群，Mesos，AWS EC2，Kubernetes分布式网络。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>在这一部分中，讨论了火花簇的体系结构。</span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;white-space:normal;background-color:rgb(255,255,255);"><span class="markup--strong markup--h3-strong" style="font-weight:inherit;">Spark集群架构</span></h3><p class="graf graf--p graf-after--h3" style="margin-top:8px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>Apache Spark遵循具有集群管理器的主/从体系结构。</span><span>火花星团有一个主人和任意数量的奴隶/工人。</span><span>一个</span></span><span class="markup--strong markup--p-strong" style="font-weight:700;"><span><span>驱动</span></span><br><span><span>程序</span></span></span><span>和</span><span class="markup--strong markup--p-strong" style="font-weight:700;">星火语境</span><span>驻留在主控守护程序和</span><span class="markup--strong markup--p-strong" style="font-weight:700;">执行者</span><span>是驻留在从属守护神。</span></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1560697270153941.png" title="1560697270153941.png" alt="1_o80WzWJShjCV1RSfWzCiQA.png" class="localImage"></p><p class="graf graf--p graf-after--figure" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span class="markup--strong markup--p-strong" style="font-weight:700;">驱动程序：</span><span><span>驱动程序是包含主程序的程序，主程序是程序的起点。</span><span>类似地，在Java中，包含public static void main（String args []）的类是驱动程序。</span><span>在Spark驱动程序中，程序驻留在主节点上，它创建并拥有Spark Context。</span><span>驱动程序通过端口4040上的Web UI公开有关正在运行的Spark应用程序的信息。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span class="markup--strong markup--p-strong" style="font-weight:700;">Spark Context：</span><span><span>它是Spark功能的主要入口点。</span><span>任何Spark驱动程序应用程序的第一步是创建Spark Context。</span><span>它允许Spark驱动程序通过资源管理器访问集群，该资源管理器可以是YARN或其他，并且可以用于在该集群上创建RDD，累加器和广播变量。</span><span>Spark Context还通过定期发送心跳消息来跟踪实时执行程序。</span><span>为了创建Spark Context，必须创建SparkConf。</span><span>SparkConf存储驱动程序应用程序将传递给Spark Context的配置参数。</span></span></p><pre class="graf graf--pre graf-after--p" style="overflow:auto;font-family:Menlo, Monaco, 'Courier New', Courier, monospace;margin-top:43px;margin-bottom:0px;padding:20px;white-space:pre-wrap;"><span>来自pyspark导入SparkContext，SparkConf </span><br><span>config = SparkConf（）。setAppName（“app_name”）。setMaster（master）</span><br><span>sc = SparkContext（conf = config）</span></pre><p class="graf graf--p graf-after--pre" style="margin-top:38px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span>master是群集的URL或以本地模式运行的“本地”字符串。</span><br><span><span>在PySpark中，已经初始化了一个spark context sc。</span><span>每个JVM只能激活一个SparkContext。</span><span>如果你想创建另一个SparkContext，那么必须首先停止</span><span>活动，然后</span><span>使用</span></span><em class="markup--em markup--p-em">sc.stop（）</em><span><span>函数完成，然后创建新的SparkContext。</span><span>如果要重用已停止的SparkContext，则可以使用</span></span><em class="markup--em markup--p-em"><span><span>-sc = SparkContext.getorcreate（conf）</span></span><br></em><span><span>来完成 &nbsp;</span><em class="markup--em markup--p-em"><span>。</span></em><span>创建Spark上下文后，Spark Driver应用程序知道必须使用哪个资源管理器并向其询问集群上的资源。</span><span>在YARN的情况下，资源管理器和节点管理器工作以为执行程序分配容器。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span class="markup--strong markup--p-strong" style="font-weight:700;">执行程序</span><span><span>&nbsp;&nbsp;：它是从属节点上RAM的一部分，其中包含数据块和要实现的任务或代码。</span><span>每个spark应用程序都有自己的执行程序进程。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span class="markup--strong markup--p-strong" style="font-weight:700;">Cluster Manager：</span><span><span>负责获取spark群集上的资源并将其分配给spark作业的服务。</span><span>Spark应用程序可以利用3种不同类型的集群管理器来分配和释放各种物理资源，例如客户端火花作业，CPU内存等的内存.Hadoop YARN，Apache Mesos或简单的独立火花集群管理器，它们中的任何一个可以在内部或云中启动，以便运行spark应用程序。</span></span></p><h3 class="graf graf--h3 graf-after--p" style="font-family:'medium-content-sans-serif-font', 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans', Geneva, Arial, sans-serif;letter-spacing:-.015em;margin:56px 0px 0px;font-size:34px;line-height:1.15;white-space:normal;background-color:rgb(255,255,255);"><span>Spark工作生命周期</span></h3><p class="graf graf--p graf-after--h3" style="margin-top:8px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>当客户端提交spark用户应用程序代码时，驱动程序隐式地将包含转换和动作的代码转换为逻辑有向非循环图（DAG）（稍后将讨论）。</span><span>然后，它将逻辑DAG转换为具有一组阶段的物理执行计划。</span><span>在创建物理执行计划之后，它会</span></span><br><span><span>在每个阶段</span><span>创建称为</span><span>任务的</span><span>小型物理执行单元</span><span>。</span><span>然后捆*绑任务以发送到Spark Cluster。</span></span><br><span><span>然后，驱动程序与集群管理器进行通信并协商资源。</span><span>然后，集群管理器代表驱动程序在工作节点上启动执行程序。</span><span>此时，驱动程序根据数据放置将任务发送到集群管理器。</span><span>在执行程序开始执行之前，它们会使用驱动程序注册自己，以便驱动程序可以全面查看所有执行程序。</span><span>现在执行程序开始执行驱动程序分配的各种任务。</span><span>在spark应用程序运行的任何时间点，驱动程序将监视运行的执行程序集。</span><span>spark系统中的驱动程序还通过跟踪缓存数据的位置，根据数据放置来安排未来的任务。</span><span>当驱动程序main（）方法退出或调用Spark的stop（）方法时</span></span><br><span>在Context中，它将终止所有执行程序并从集群管理器中释放资源。</span></p><p class="graf graf--p graf-after--p graf--trailing" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;white-space:normal;background-color:rgb(255,255,255);"><span><span>这就是这一部分。</span><span>在下一部分中，我们将讨论Spark RDD及其操作。</span></span></p><p class="graf graf--p graf-after--p" style="margin-top:29px;margin-bottom:0px;font-family:'medium-content-serif-font', Georgia, Cambria, 'Times New Roman', Times, serif;font-size:21px;line-height:1.58;letter-spacing:-.003em;"><br></p></section><p><br></p><p><br></p>
    </div>
    
    
    <p class="pc_current ask-tip">登录后可下载附件，请<a href="https://auth.huaweicloud.com/authui/login?service=https://bbs.huaweicloud.com/blogs/114071#attachment&amp;locale=zh-cn">登录</a>或者<a href="https://reg.huaweicloud.com/registerui/public/custom/register.html?locale=zh-cn&amp;service=https://bbs.huaweicloud.com#/register">注册</a></p>

    <!-- 版权声明 start -->
    
   
    
    <!-- 版权声明 end -->

    <div class="blog-menu-footer m-blog-menu-footer-bottom">
        
    </div>
</div></div>