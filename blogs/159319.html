<link rel="stylesheet" type="text/css" href="../css/blog.css"><div class="cloud-blog-detail-content-wrap the_height"><div class="cloud-blog-detail-content-wrap">
    <div class="cloud-blog-detail-content blog-content-block-0" id="blogContent">
        <p>原文链接:（Manu Shaurya<span style="color: rgba(0, 0, 0, 0.84);">）</span></p><p><a rel="nofollow" href="https://medium.com/@manushaurya/mcculloch-pitts-neuron-vs-perceptron-model-8668ed82c36">https://medium.com/@manushaurya/mcculloch-pitts-neuron-vs-perceptron-model-8668ed82c36</a> </p><h2>McCulloch-Pitts神经元与Perceptron模型</h2><p>McCulloch-Pitts神经元缩写为MP Neuron，是人工神经网络的基本组成部分。与生物神经元类似，MP神经元和Perceptron模型都接受输入并对其进行处理以提供输出，尽管它们在处理方式上有所不同，我们将在下文中对此进行介绍。</p><p><br></p><h3>生物神经元</h3><p>但是首先，我们将看到生物神经元是如何工作的。首先，神经元可以分为三个基本单元，树突，细胞体（也称为Soma）和轴突。对于我们执行的每项任务，在我们的大脑中，这些神经元的特定网络发出信号，这些信号通过突触末端到达树突，再穿过细胞体到达轴突，然后进一步传递到另一个神经元。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1586832858503001882.png"></p><p><br></p><p>生物神经元</p><h3>McCulloch-Pitts神经元模型</h3><p>由沃伦·麦卡洛、克（Warren McCulloch）和沃尔、特·皮茨（Walter Pitts）于1943年提出，该模型模仿了生物神经元的功能，因此也称为人工神经元。人工神经元接受二进制输入，并根据可调整的某个阈值产生二进制输出。这主要可用于分类问题。</p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1586832874123028023.png"></p><p><br></p><p>人工神经元（看起来类似于生物神经元，对吗？）</p><p>在获取各种输入后，函数将它们汇总，并根据汇总做出决策。聚合仅表示这些二进制输入的总和。如果合计值超过阈值，则输出为1，否则为0。</p><h3>感知器模型</h3><p>该模型由弗兰克·罗森布拉特（Frank Rosenblatt）在1957年开发。这是我们之前看到的“人工神经元”模型的略微调整版本。在这里，神经元也称为线性阈值单元（LTU）。该模型可以处理非布尔值，其中每个输入连接都与权重关联。此处，函数计算加权和，并根据提供的阈值提供二进制输出。</p><p><br></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1586832885899049434.png"></p><p>如上图所示，感知器中的每个输入连接均与权重相关联，该权重确定该输入对输出产生的影响程度。</p><h3>MP神经元模型和感知器模型之间的比较</h3><ul class=" list-paddingleft-2" style="list-style-type: none;"><li><p>MP Neuron模型和Perceptron模型都可以处理线性可分离的数据。</p></li><li><p>MP Neuron模型仅接受布尔输入，而Perceptron模型可以处理任何实际输入。</p></li><li><p>在MP Neuron模型中，输入未加权，这使该模型的灵活性降低。另一方面，Perceptron模型可以权衡提供的输入。</p></li><li><p>在使用这两个模型时，我们可以调整阈值输入以使模型适合我们的数据集。</p></li></ul><p>您可以在<a href="http://goo.gl/Ul4mxW" class="bx fm hz ia ib ic" target="_blank" style="box-sizing: inherit; text-decoration-line: none; -webkit-tap-highlight-color: transparent; background-repeat: repeat-x; background-image: url(&quot;data:image/svg+xml;utf8,<svg preserveAspectRatio=\&quot;none\&quot; viewBox=\&quot;0 0 1 1\&quot; xmlns=\&quot;http://www.w3.org/2000/svg\&quot;><line x1=\&quot;0\&quot; y1=\&quot;0\&quot; x2=\&quot;1\&quot; y2=\&quot;1\&quot; stroke=\&quot;rgba(0, 0, 0, 0.84)\&quot; ></line></svg>&quot;); background-size: 1px 1px; background-position: 0px calc(1em + 1px);"><span style=""><span style="">此处</span></span></a><span style=""><span style="">找</span></span>到发表的论文McCulloch和Pitts&nbsp;。</p><p><span style="color: rgb(0, 176, 80);">/*-----------------------------------------------------------------------------------------------------------*/</span></p><p><span style="color: rgb(0, 176, 80);"></span></p><p><strong>感知器</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8">https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8</a> </p><pre class="brush:plain;toolbar:false">$${\displaystyle&nbsp;t=f(\sum&nbsp;_{i=1}^{n}{{w}_{i}{x}_{i}+b})=f(\mathbf&nbsp;{w}&nbsp;^{T}\mathbf&nbsp;{x}&nbsp;)}&nbsp;$$
$${\displaystyle&nbsp;w(j):=w(j)+{\alpha&nbsp;(y-f(x))}{x(j)}\quad&nbsp;(j=1,\ldots&nbsp;,n)}&nbsp;$$</pre><p><strong>支持向量机</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA">https://zh.wikipedia.org/wiki/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA</a> </p><pre class="brush:plain;toolbar:false"><br></pre><p><strong>逻辑回归</strong></p><p><a rel="nofollow" href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a> </p><pre class="brush:plain;toolbar:false">$$&nbsp;P(t)={\frac&nbsp;&nbsp;{1}{1+e^{{-t}}}}&nbsp;$$</pre><p><strong>Softmax函数</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0">https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0</a> </p><pre class="brush:plain;toolbar:false">$$&nbsp;{\displaystyle&nbsp;\sigma&nbsp;(\mathbf&nbsp;{z}&nbsp;)_{j}={\frac&nbsp;{e^{z_{j}}}{\sum&nbsp;_{k=1}^{K}e^{z_{k}}}}}&nbsp;$$</pre><p><span style="color: rgb(0, 176, 80);"><strong style="color: rgb(34, 34, 34); font-size: 15.008px; white-space: normal; background-color: rgb(255, 255, 255);">人工神经网络(ANN)</strong></span><br></p><p><span style="color: rgb(0, 176, 80);"><strong style="color: rgb(34, 34, 34); font-size: 15.008px; white-space: normal; background-color: rgb(255, 255, 255);"><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C</a> </strong></span></p><p><span style="color: rgb(0, 0, 0);"><strong>卷积神经网络(CNN)</strong></span></p><pre class="brush:plain;toolbar:false">卷积神经网络由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，同时也包括关联权重和池化层（pooling&nbsp;layer）。</pre><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C</a></p><p><a rel="nofollow" href="https://cezannec.github.io/Convolutional_Neural_Networks/">https://cezannec.github.io/Convolutional_Neural_Networks/</a></p><p><a rel="nofollow" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53</a></p><p><a rel="nofollow" href="https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add">https://towardsdatascience.com/basics-of-the-classic-cnn-a3dce1225add</a></p><p><a rel="nofollow" href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/">https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/</a></p><p><a rel="nofollow" href="https://vinodsblog.com/2018/10/15/everything-you-need-to-know-about-convolutional-neural-networks/">https://vinodsblog.com/2018/10/15/everything-you-need-to-know-about-convolutional-neural-networks/</a></p><p><span style="color: rgb(0, 176, 80);"></span><strong>完全卷积神经网络(FCN)</strong></p><p><span style="color: rgb(0, 176, 80);"><a rel="nofollow" href="https://arxiv.org/abs/1907.11371">https://arxiv.org/abs/1907.11371</a></span></p><p><span style="color: rgb(0, 176, 80);"><span style="display: inline; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-stretch: inherit; font-size: 13px; font-family: arial, sans-serif; color: rgb(102, 0, 153); line-height: inherit; background: none rgb(245, 245, 245); border: 0px; margin: 0px; padding: 0px; text-decoration-line: none;"><span style=""><a rel="nofollow" href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_segmentation.html" style="display: inline; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-stretch: inherit; font-size: 13px; font-family: arial, sans-serif; color: rgb(102, 0, 153); line-height: inherit; background: none rgb(245, 245, 245); border: 0px; margin: 0px; padding: 0px; text-decoration-line: none; white-space: normal;">https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_segmentation.html</a></span></span></span></p><pre class="brush:plain;toolbar:false">A&nbsp;Fully&nbsp;Convolutional&nbsp;neural&nbsp;network&nbsp;(FCN)&nbsp;is&nbsp;a&nbsp;normal&nbsp;CNN,&nbsp;where&nbsp;the&nbsp;last&nbsp;fully&nbsp;connected&nbsp;layer&nbsp;is&nbsp;substituted&nbsp;by&nbsp;another&nbsp;convolution&nbsp;layer&nbsp;with&nbsp;a&nbsp;large&nbsp;"receptive&nbsp;field".</pre><p><span style="color: rgb(0, 176, 80);"><span style="display: inline; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-stretch: inherit; font-size: 13px; font-family: arial, sans-serif; color: rgb(102, 0, 153); line-height: inherit; background: none rgb(245, 245, 245); border: 0px; margin: 0px; padding: 0px; text-decoration-line: none;"></span></span><strong>受限玻尔兹曼机(RBM)</strong></p><p><strong><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA">https://zh.wikipedia.org/wiki/%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA</a></strong></p><p style="white-space: normal;"><a rel="nofollow" href="https://blog.csdn.net/hustqb/article/details/84847230">https://blog.csdn.net/hustqb/article/details/84847230</a></p><p style="white-space: normal;"><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/22794772">https://zhuanlan.zhihu.com/p/22794772</a></p><p style="white-space: normal;"><a rel="nofollow" href="https://www.jiqizhixin.com/articles/2018-05-07-7">https://www.jiqizhixin.com/articles/2018-05-07-7</a></p><p style="white-space: normal;"><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA">https://zh.wikipedia.org/wiki/%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA</a></p><pre class="brush:plain;toolbar:false">受限玻尔兹曼机（英語：restricted&nbsp;Boltzmann&nbsp;machine,&nbsp;RBM）是一种可通过输入数据集学习概率分布的随机生成神经网络。</pre><p><strong> 自编码器（AE）</strong></p><p><strong><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8">https://zh.wikipedia.org/wiki/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8</a> </strong></p><p><strong>深度信念网络（DBN）</strong></p><p><strong><a rel="nofollow" href="https://blog.csdn.net/a819825294/article/details/53608141">https://blog.csdn.net/a819825294/article/details/53608141</a></strong></p><p><strong>循环神经网络(RNN)</strong></p><p><strong><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C</a> </strong></p><p><a rel="nofollow" href="https://towardsdatascience.com/recurrent-neural-networks-d4642c9bc7ce">https://towardsdatascience.com/recurrent-neural-networks-d4642c9bc7ce</a></p><p><a rel="nofollow" href="https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9">https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9</a></p><p><a rel="nofollow" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p><p><a rel="nofollow" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks">https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks</a></p><p><a rel="nofollow" href="https://www.tensorflow.org/guide/keras/rnn">https://www.tensorflow.org/guide/keras/rnn</a></p><p><a rel="nofollow" href="https://machinelearningmastery.com/recurrent-neural-network-algorithms-for-deep-learning/">https://machinelearningmastery.com/recurrent-neural-network-algorithms-for-deep-learning/</a></p><p><a rel="nofollow" href="https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/">https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/</a></p><pre class="brush:plain;toolbar:false">循环神经网络（Recurrent&nbsp;neural&nbsp;network：RNN）是神經網絡的一種。
单纯的RNN因为无法处理随着递归，权重指数级爆炸或梯度消失问题，难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。[1][2]

时间循环神经网络可以描述动态时间行为，因为和前馈神经网络（feedforward&nbsp;neural&nbsp;network）接受较特定结构的输入不同，
RNN将状态在自身网络中循环传递，因此可以接受更广泛的时间序列结构输入。手写识别是最早成功利用RNN的研究结果</pre><p><strong>長短期記憶(<span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">Long Short-Term Memory</span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">，</span><span style="color: rgb(34, 34, 34); font-size: 15.008px; background-color: rgb(255, 255, 255);">LSTM</span>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6">https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6</a>&nbsp;</p><pre class="brush:plain;toolbar:false">是一种时间循环神经网络（RNN）
由于独特的设计结构，LSTM适合于处理和预测时间序列中间隔和延迟非常长的重要事件。</pre><p><strong>生成对抗网络(<span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)"><strong>G</strong>enerative&nbsp;<strong>A</strong>dversarial&nbsp;<strong>N</strong>etwork</span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">，</span><span style="color: rgb(34, 34, 34); font-size: 15.008px; background-color: rgb(255, 255, 255);">GAN</span>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C">https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C</a></p><pre class="brush:plain;toolbar:false">是非监督式学习的一种方法，通过让两个神经網路相互博弈的方式进行学习。</pre><p><strong>决策树</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0">https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0</a></p><p>&nbsp;<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91">https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91</a></p><pre class="brush:plain;toolbar:false">统计学，数据挖掘和机器学习中的决策树训练，使用决策树作为预测模型来预测样本的类标。
这种决策树也称作分类树或回归树。在这些树的结构里，&nbsp;叶子节点给出类标而内部节点代表某个属性。
在决策分析中，一棵决策树可以明确地表达决策的过程。在数据挖掘中，一棵决策树表达的是数据而不是决策。</pre><p><strong>ID3算法</strong></p><p>&nbsp;<a rel="nofollow" href="https://zh.wikipedia.org/wiki/ID3%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/ID3%E7%AE%97%E6%B3%95</a></p><pre class="brush:plain;toolbar:false">D3算法（Iterative&nbsp;Dichotomiser&nbsp;3&nbsp;迭代二叉树3代）是一个由Ross&nbsp;Quinlan发明的用于决策树的算法。</pre><p><strong>C4.5算法</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/C4.5%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/C4.5%E7%AE%97%E6%B3%95</a></p><pre class="brush:plain;toolbar:false">C4.5算法是由Ross&nbsp;Quinlan（英语：Ross&nbsp;Quinlan）开发的用于产生决策树的算法。该算法是对Ross&nbsp;Quinlan之前开发的ID3算法的一个扩展。</pre><p><strong style="color: rgb(34, 34, 34); font-size: 15.008px; white-space: normal; background-color: rgb(255, 255, 255);">CART</strong></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/36108972">https://zhuanlan.zhihu.com/p/36108972</a> </p><p><a rel="nofollow" href="https://blog.csdn.net/ACdreamers/article/details/44664481">https://blog.csdn.net/ACdreamers/article/details/44664481</a> </p><p><strong>随机森林</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97">https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97</a></p><pre class="brush:plain;toolbar:false">在機器學習中，隨機森林是一個包含多個決策樹的分類器，並且其輸出的類別是由個別樹輸出的類別的眾數而定。
這個方法則是結合Breimans的"Bootstrap&nbsp;aggregating"想法和Ho的"random&nbsp;subspace&nbsp;method"以建造決策樹的集合。</pre><p><strong>Bagging算法(<strong style="white-space: normal;">Bootstrap aggregating,<span style="font-family: &quot;Microsoft YaHei&quot;; font-size: 15.008px;">引导聚集算法，又称</span><strong style="font-family: &quot;Microsoft YaHei&quot;; font-size: 15.008px; white-space: normal;">装袋算</strong></strong>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/Bagging%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/Bagging%E7%AE%97%E6%B3%95</a></p><p><a rel="nofollow" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">https://en.wikipedia.org/wiki/Bootstrap_aggregating</a></p><pre class="brush:plain;toolbar:false">给定一个大小为n的训练集D，Bagging算法从中均匀、有放回地（即使用自助抽样法）选出m个大小为n′的子集Di，
作为新的训练集。在这m个训练集上使用分类、回归等算法，则可得到m个模型，再通过取平均值、取多数票等方法，即可得到Bagging的结果。</pre><p><strong>梯度提升树<span style="color: rgb(34, 34, 34); font-size: 15.008px; background-color: rgb(255, 255, 255);">（GBT或GBDT）</span></strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%8A%80%E6%9C%AF">https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%8A%80%E6%9C%AF</a> </p><pre class="brush:plain;toolbar:false">梯度提升（梯度增强）是一种用于回归和分类问题的机器学习技术，其产生的预测模型是弱预测模型的集成，
如采用典型的决策树&nbsp;作为弱预测模型，这时则为梯度提升树（GBT或GBDT）。
像其他提升方法一样，它以分阶段的方式构建模型，但它通过允许对任意可微分损失函数进行优化作为对一般提升方法的推广。</pre><p><strong>AdaBoost</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/AdaBoost">https://zh.wikipedia.org/wiki/AdaBoost</a></p><pre class="brush:plain;toolbar:false">AdaBoost方法的自适应在于：前一个分类器分错的样本会被用来训练下一个分类器。</pre><p><strong><span style="color: rgb(34, 34, 34); font-size: 15.008px; background-color: rgb(255, 255, 255);">Boosting</span></strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95">https://zh.wikipedia.org/wiki/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95</a></p><p><strong>线性回归（<strong style="color: rgb(34, 34, 34); font-size: 15.008px; white-space: normal; background-color: rgb(255, 255, 255);">linear regression</strong>）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/zh-sg/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8">https://zh.wikipedia.org/zh-sg/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8</a></p><p><strong>岭回归（Ridge regression）</strong></p><p><strong><a rel="nofollow" href="https://blog.csdn.net/google19890102/article/details/27228279">https://blog.csdn.net/google19890102/article/details/27228279</a> </strong></p><p><strong>Lasso算法(<strong style="color: rgb(34, 34, 34); font-size: 15.008px; white-space: normal; background-color: rgb(255, 255, 255);">least absolute shrinkage and selection operator</strong><span style="color: rgb(34, 34, 34); font-size: 15.008px; background-color: rgb(255, 255, 255);">，又译最小绝对值收敛和选择算子、套索算法</span>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/Lasso%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/Lasso%E7%AE%97%E6%B3%95</a></p><p><strong>K-近邻算法(<strong style="color: rgb(34, 34, 34); font-size: 15.008px; white-space: normal; background-color: rgb(255, 255, 255);">KNN)</strong></strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95</a></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1587037533002002751.png"></p><p><strong>贝叶斯定理（Bayes' theorem）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86">https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86</a></p><pre class="brush:plain;toolbar:false">葉斯定理（英語：Bayes'&nbsp;theorem）是機率論中的一個定理，描述在已知一些条件下，某事件的发生機率。</pre><p><strong>朴素贝叶斯分类器</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8">https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8</a></p><pre class="brush:plain;toolbar:false">在机器学习中，單純貝氏分类器是一系列以假设特征之间强（朴素）独立下运用贝叶斯定理为基础的简单概率分类器（英语：probabilistic&nbsp;classifier）。</pre><p><strong>正态贝叶斯分类器</strong></p><p><strong><a rel="nofollow" href="https://blog.csdn.net/neu_chenguangq/article/details/79288905">https://blog.csdn.net/neu_chenguangq/article/details/79288905</a> </strong></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/47390725">https://zhuanlan.zhihu.com/p/47390725</a> </p><p><a rel="nofollow" href="https://blog.csdn.net/BBZZ2/article/details/50915660">https://blog.csdn.net/BBZZ2/article/details/50915660</a> </p><p><strong>贝叶斯网络</strong></p><p><strong><a rel="nofollow" href="https://zh.wikipedia.org/wiki/貝氏網路">https://zh.wikipedia.org/wiki/貝氏網路</a></strong></p><p><a rel="nofollow" href="https://zh.m.wikipedia.org/zh-hans/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF">https://zh.m.wikipedia.org/zh-hans/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF</a></p><p><img src="https://bbs-img.huaweicloud.com/blogs/img/1587036103126058746.png"></p><pre class="brush:plain;toolbar:false">貝氏網路（Bayesian&nbsp;network），又稱信念網絡（belief&nbsp;network）或是有向無環圖模型（directed&nbsp;acyclic&nbsp;graphical&nbsp;model），
是一種機率圖型模型，藉由有向無環圖（directed&nbsp;acyclic&nbsp;graphs,&nbsp;or&nbsp;DAGs）中得知一組隨機變數{X1,X2,...,Xn}
及其n組條件機率分配（conditional&nbsp;probability&nbsp;distributions,&nbsp;or&nbsp;CPDs）的性質。</pre><p><strong>隐含狄利克雷分布(<span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">Latent Dirichlet allocation</span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">，</span><strong style="color: rgb(34, 34, 34);font-size: 15.008px;white-space: normal;background-color: rgb(255, 255, 255)">LDA</strong>)</strong></p><p>&nbsp;<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E9%9A%90%E5%90%AB%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83">https://zh.wikipedia.org/wiki/%E9%9A%90%E5%90%AB%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83</a></p><pre class="brush:plain;toolbar:false">是一种主题模型，它可以将文档集中每篇文档的主题按照概率分布的形式给出。
同时它是一种无监督学习算法，在训练时不需要手工标注的训练集，需要的仅仅是文档集以及指定主题的数量k即可。
此外LDA的另一个优点则是，对于每一个主题均可找出一些词语来描述它。</pre><p><strong>Kernel Linear Discriminant Analysis,KLDA</strong></p><p><a rel="nofollow" href="https://www.sciencedirect.com/science/article/pii/S187705091502027X">https://www.sciencedirect.com/science/article/pii/S187705091502027X</a> </p><p><a rel="nofollow" href="https://www.researchgate.net/publication/221017649_An_Iterative_Algorithm_for_KLDA_Classifier">https://www.researchgate.net/publication/221017649_An_Iterative_Algorithm_for_KLDA_Classifier</a> </p><p><strong>主成分分析(<span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)"><strong>Principal components analysis</strong></span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">，</span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)"><strong>PCA</strong></span>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90">https://zh.wikipedia.org/wiki/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90</a></p><p><strong>核主成分分析(<span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">kernel principal component analysis</span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">，</span><span style="color: rgb(34, 34, 34);font-size: 15.008px;background-color: rgb(255, 255, 255)">kernel PCA</span>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%A0%B8%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90">https://zh.wikipedia.org/wiki/%E6%A0%B8%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90</a></p><p><strong>流行学习(<span style="color: rgb(60, 64, 67); font-family: arial, sans-serif; font-size: 14px; background-color: rgb(255, 255, 255);">manifold learning</span>)</strong><br></p><p><a rel="nofollow" href="https://en.wikipedia.org/wiki/Manifold_alignment">https://en.wikipedia.org/wiki/Manifold_alignment</a></p><p><a rel="nofollow" href="https://blog.csdn.net/chl033/article/details/6107042">https://blog.csdn.net/chl033/article/details/6107042</a> </p><p><a rel="nofollow" href="https://leovan.me/cn/2018/03/manifold-learning/">https://leovan.me/cn/2018/03/manifold-learning/</a> </p><p><strong>局部线性嵌入(Locally Linear Embedding, 简称为LLE)</strong></p><p><strong><a rel="nofollow" href="https://www.cnblogs.com/pinard/p/6266408.html">https://www.cnblogs.com/pinard/p/6266408.html</a></strong></p><p><a rel="nofollow" href="https://blog.csdn.net/VictoriaW/article/details/78496963">https://blog.csdn.net/VictoriaW/article/details/78496963</a></p><p><a rel="nofollow" href="https://leoncuhk.gitbooks.io/feature-engineering/feature-extracting10.html">https://leoncuhk.gitbooks.io/feature-engineering/feature-extracting10.html</a> </p><p><a rel="nofollow" href="https://www.imooc.com/article/44215">https://www.imooc.com/article/44215</a> </p><p><strong>拉普拉斯特征映射（LaplacianEigenmaps）</strong></p><p><a rel="nofollow" href="https://blog.csdn.net/qrlhl/article/details/78066994">https://blog.csdn.net/qrlhl/article/details/78066994</a> </p><p><a rel="nofollow" href="https://blog.csdn.net/yujianmin1990/article/details/48420483">https://blog.csdn.net/yujianmin1990/article/details/48420483</a></p><p><strong>等距特征映射(Isomap)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%AD%89%E8%B7%9D%E7%89%B9%E5%BE%81%E6%98%A0%E5%B0%84">https://zh.wikipedia.org/wiki/%E7%AD%89%E8%B7%9D%E7%89%B9%E5%BE%81%E6%98%A0%E5%B0%84</a> </p><p><strong>局部保持投影法(Locality Preserving Projections, LPP）</strong></p><p><a rel="nofollow" href="https://www.zhihu.com/question/41453753">https://www.zhihu.com/question/41453753</a> </p><p><a rel="nofollow" href="https://blog.csdn.net/u010555688/article/details/39028471">https://blog.csdn.net/u010555688/article/details/39028471</a> </p><p><a rel="nofollow" href="https://blog.csdn.net/evillist/article/details/74981761">https://blog.csdn.net/evillist/article/details/74981761</a> </p><p><strong>概率图模型（Graphical Model）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%9C%96%E6%A8%A1%E5%BC%8F">https://zh.wikipedia.org/wiki/%E5%9C%96%E6%A8%A1%E5%BC%8F</a></p><pre class="brush:plain;toolbar:false">在概率论、統計學及機器學習中，概率图模型（Graphical&nbsp;Model）是用圖論方法以表現數個獨立隨機變數之關聯的一種建模法。
一个p个節點的图中，节点i对应一个隨機變數，记为Xi。概率图模型被广泛地应用于贝叶斯统计与机器学习中。</pre><p><strong>隐马尔可夫模型（Hidden Markov Model，HMM）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B">https://zh.wikipedia.org/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B</a></p><pre class="brush:plain;toolbar:false">是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。
其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。</pre><p><strong>条件随机场（conditional random field，簡稱 CRF）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%A2%9D%E4%BB%B6%E9%9A%A8%E6%A9%9F%E5%9F%9F">https://zh.wikipedia.org/wiki/%E6%A2%9D%E4%BB%B6%E9%9A%A8%E6%A9%9F%E5%9F%9F</a></p><pre class="brush:plain;toolbar:false">是一種鑑別式機率模型，是随机场的一种，常用於標注或分析序列資料，如自然語言文字或是生物序列。
如同马尔可夫随机场，條件隨機場為無向性之圖模型，圖中的頂點代表隨機變數，頂點間的連線代表隨機變數間的相依關係，
在條件隨機場當中，隨機變數&nbsp;Y&nbsp;的分佈為條件機率，給定的觀察值則為隨機變數&nbsp;X。原則上，條件隨機場的圖模型佈局是可以任意給定的，
一般常用的佈局是鏈結式的架構，鏈結式架構不論在訓練（training）、推論（inference）、或是解碼（decoding）上，都存在有效率的演算法可供演算。

條件隨機場跟隱藏式馬可夫模型常被一起提及，條件隨機場對於輸入和輸出的機率分佈，沒有如隱藏式馬可夫模型那般強烈的假設存在。
线性链条件随机场应用于标注问题是由Lafferty等人与2001年提出的[1]</pre><p><strong>层次聚类(<strong style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium; white-space: normal;">HCA</strong>)</strong></p><p><a rel="nofollow" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">https://en.wikipedia.org/wiki/Hierarchical_clustering</a></p><pre class="brush:plain;toolbar:false">在数据挖掘和统计中，层次聚类（也称为层次聚类分析或HCA）是一种聚类分析的方法，旨在建立聚类的层次。</pre><p><strong>K-平均算法（k-means clustering）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/K-%E5%B9%B3%E5%9D%87%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/K-%E5%B9%B3%E5%9D%87%E7%AE%97%E6%B3%95</a></p><pre class="brush:plain;toolbar:false">源于信号处理中的一种向量量化方法，现在则更多地作为一种聚类分析方法流行于数据挖掘领域。
k-平均聚类的目的是：把n{\displaystyle&nbsp;n}nn个点（可以是样本的一次观察或一个实例）划分到k个聚类中，
使得每个点都属于离他最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。这个问题将归结为一个把数据空间划分为Voronoi&nbsp;cells的问题。
这个问题在计算上是NP困难的，不过存在高效的启发式算法。一般情况下，都使用效率比较高的启发式算法，它们能够快速收敛于一个局部最优解。
这些算法通常类似于通过迭代优化方法处理高斯混合分布的最大期望算法（EM算法）。
而且，它们都使用聚类中心来为数据建模；然而k-平均聚类倾向于在可比较的空间范围内寻找聚类，期望-最大化技术却允许聚类有不同的形状。</pre><p><strong>DBSCAN（Density-based spatial clustering of applications with noise）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/DBSCAN">https://zh.wikipedia.org/wiki/DBSCAN</a></p><pre class="brush:plain;toolbar:false">聚類分析算法，&nbsp;這個算法是以密度為本的：給定某空間裡的一個點集合，這算法能把附近的點分成一組（有很多相鄰點的點），
並標記出位於低密度區域的局外點（最接近它的點也十分遠）。
DBSCAN&nbsp;是最常用的聚類分析算法之一，也是科學文章中最常引用的聚類分析算法之一。</pre><p><strong>OPTICS(<span style="color: rgb(34, 34, 34); font-size: 15.008px; background-color: rgb(255, 255, 255);">Ordering points to identify the clustering structure</span>)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/OPTICS">https://zh.wikipedia.org/wiki/OPTICS</a></p><pre class="brush:plain;toolbar:false">基于密度的聚类分析算法
OPTICS并不依赖全局变量来确定聚类，而是将空间上最接近的点相邻排列，以得到数据集合中的对象的线性排序。[2]
排序后生成的序列存储了与相邻点之间的距离，并最终生成了一个&nbsp;dendrogram&nbsp;。OPTICS算法的思路与DBSCAN类似，
但是解决了DBSCAN的一个主要弱点，即如何在密度变化的数据中取得有效的聚类。同时&nbsp;OPTICS也避免了多数聚类算法中对输入参数敏感的问题。</pre><p><strong>Mean shift</strong></p><p><a rel="nofollow" href="https://en.wikipedia.org/wiki/Mean_shift">https://en.wikipedia.org/wiki/Mean_shift</a></p><pre class="brush:plain;toolbar:false">均值平移是一种用于定位密度函数最大值的非参数&nbsp;特征空间分析技术，即所谓的模式寻找算法。</pre><p><strong>谱聚类（spectral clustering）</strong></p><p><a rel="nofollow" href="https://www.cnblogs.com/pinard/p/6221564.html">https://www.cnblogs.com/pinard/p/6221564.html</a></p><p><a rel="nofollow" href="https://www.jiqizhixin.com/graph/technologies/48f118d7-d49d-433a-a127-9912a40aaae6">https://www.jiqizhixin.com/graph/technologies/48f118d7-d49d-433a-a127-9912a40aaae6</a></p><p><a rel="nofollow" href="https://cloud.tencent.com/developer/article/1189421">https://cloud.tencent.com/developer/article/1189421</a></p><p><strong>最大期望（EM）算法,最大期望演算法（Expectation-maximization algorithm，又譯期望最大化算法）</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95">https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B%E7%AE%97%E6%B3%95</a></p><pre class="brush:plain;toolbar:false">在统计计算中，最大期望（EM）算法是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐变量。</pre><p><strong>策略迭代(Policy Iteration)&nbsp;</strong></p><p><strong><a rel="nofollow" href="https://en.wikipedia.org/wiki/Markov_decision_process#Policy_iteration" style="white-space: normal;">https://en.wikipedia.org/wiki/Markov_decision_process#Policy_iteration</a></strong></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/34006925">https://zhuanlan.zhihu.com/p/34006925</a></p><p><a rel="nofollow" href="https://www.jiqizhixin.com/graph/technologies/1a28fecc-5783-4128-9063-ea9f0e94f474">https://www.jiqizhixin.com/graph/technologies/1a28fecc-5783-4128-9063-ea9f0e94f474</a></p><p><a rel="nofollow" href="https://www.cnblogs.com/huangyc/p/10381184.html">https://www.cnblogs.com/huangyc/p/10381184.html</a></p><p><strong>值迭代（Value Iteration）</strong></p><p><strong style="white-space: normal;"></strong><a rel="nofollow" href="https://en.wikipedia.org/wiki/Markov_decision_process#value_iteration">https://en.wikipedia.org/wiki/Markov_decision_process#value_iteration</a></p><p><strong>蒙特卡罗方法</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%96%B9%E6%B3%95">https://zh.wikipedia.org/wiki/%E8%92%99%E5%9C%B0%E5%8D%A1%E7%BE%85%E6%96%B9%E6%B3%95</a></p><pre class="brush:plain;toolbar:false">蒙特卡罗方法（英語：Monte&nbsp;Carlo&nbsp;method），也称统计模拟方法，是1940年代中期由于科学技术的发展和电子计算机的发明，
而提出的一种以概率统计理论为指导的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。
##&nbsp;在解决实际问题的时候应用蒙特卡罗方法主要有两部分工作：
*&nbsp;用蒙特卡罗方法模拟某一过程时，需要产生各种概率分布的随机变量。
*&nbsp;用统计方法把模型的数字特征估计出来，从而得到实际问题的数值解。</pre><p><br></p><p><strong>时序差分算法(Temporal-Difference Learning)&nbsp;</strong></p><p><a rel="nofollow" href="https://www.jianshu.com/p/0bfeb09b7d5f">https://www.jianshu.com/p/0bfeb09b7d5f</a></p><p><a rel="nofollow" href="https://www.jiqizhixin.com/graph/technologies/7411ce5b-c024-49eb-a565-3e1718adeb8a">https://www.jiqizhixin.com/graph/technologies/7411ce5b-c024-49eb-a565-3e1718adeb8a</a></p><p><a rel="nofollow" href="https://blog.csdn.net/qq_30159351/article/details/72896220">https://blog.csdn.net/qq_30159351/article/details/72896220</a></p><p><a rel="nofollow" href="https://www.cnblogs.com/steven-yang/p/6516818.html">https://www.cnblogs.com/steven-yang/p/6516818.html</a></p><p><br></p><p><strong>SARSA算法</strong></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/29283927">https://zhuanlan.zhihu.com/p/29283927</a></p><p><a rel="nofollow" href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/3-1-tabular-sarsa1/">https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/3-1-tabular-sarsa1/</a></p><p><a rel="nofollow" href="http://zuzhiang.cn/2019/10/10/sarsa/">http://zuzhiang.cn/2019/10/10/sarsa/</a></p><p><a rel="nofollow" href="https://cloud.tencent.com/developer/article/1602094">https://cloud.tencent.com/developer/article/1602094</a></p><p><strong>Q学习(Q-Learning)</strong></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C</a></p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/Q%E5%AD%A6%E4%B9%A0">https://zh.wikipedia.org/wiki/Q%E5%AD%A6%E4%B9%A0</a></p><p><a rel="nofollow" href="https://blog.csdn.net/qq_30615903/article/details/80739243">https://blog.csdn.net/qq_30615903/article/details/80739243</a></p><p><a rel="nofollow" href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/2-2-tabular-q1/">https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/2-2-tabular-q1/</a></p><p><a rel="nofollow" href="https://www.jiqizhixin.com/articles/2018-04-17-3">https://www.jiqizhixin.com/articles/2018-04-17-3</a></p><p><a rel="nofollow" href="https://cloud.tencent.com/developer/article/1012013">https://cloud.tencent.com/developer/article/1012013</a></p><pre class="brush:plain;toolbar:false">Q-学习是强化学习的一种方法。Q-学习就是要記錄下学习過的政策，因而告诉智能体什么情况下采取什么行动會有最大的獎勵值。
Q-学习不需要对环境进行建模，即使是对带有随机因素的转移函数或者奖励函数也不需要进行特别的改动就可以进行。
对于任何有限的馬可夫決策過程（FMDP），Q-学习可以找到一个可以最大化所有步骤的奖励期望的策略。
[1]，在给定一个部分随机的策略和无限的探索时间，Q-学习可以给出一个最佳的动作选择策略。
「Q」这个字母在强化学习中表示一个动作的品质（quality)。[2]</pre><p><strong>DQN（Deep Q-Learning）</strong></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/26052182">https://zhuanlan.zhihu.com/p/26052182</a></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/35882937">https://zhuanlan.zhihu.com/p/35882937</a></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/21262246">https://zhuanlan.zhihu.com/p/21262246</a></p><p><a rel="nofollow" href="https://zhuanlan.zhihu.com/p/91685011">https://zhuanlan.zhihu.com/p/91685011</a></p><p><a rel="nofollow" href="https://medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4">https://medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4</a></p><p>//</p><p><a rel="nofollow" href="https://blog.csdn.net/SIGAI_CSDN/article/details/80991031">https://blog.csdn.net/SIGAI_CSDN/article/details/80991031</a></p><p>//</p><p>伯努利分布</p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83">https://zh.wikipedia.org/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83</a></p><p><a rel="nofollow" href="https://blog.csdn.net/kingzone_2008/article/details/80584743">https://blog.csdn.net/kingzone_2008/article/details/80584743</a></p><p><a rel="nofollow" href="https://blog.csdn.net/solo_sky/article/details/47777943">https://blog.csdn.net/solo_sky/article/details/47777943</a></p><p>泊松分布</p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88">https://zh.wikipedia.org/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88</a></p><p>最大似然估计</p><p><a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1">https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1</a></p><p><br></p><p><br></p><p></p><p><br></p><p><br></p><p><br></p>
    </div>
    
    
    <p class="pc_current ask-tip">登录后可下载附件，请<a href="https://auth.huaweicloud.com/authui/login?service=https://bbs.huaweicloud.com/blogs/159319#attachment&amp;locale=zh-cn">登录</a>或者<a href="https://reg.huaweicloud.com/registerui/public/custom/register.html?locale=zh-cn&amp;service=https://bbs.huaweicloud.com#/register">注册</a></p>

    <!-- 版权声明 start -->
    
   
    
    <!-- 版权声明 end -->

    <div class="blog-menu-footer m-blog-menu-footer-bottom">
        
        <a class="common-blog-menu-btn title_banner_7" target="_self" rel="noopener noreferrer" mate_data_ts="bbs_blogdetail_blogTag.click.人工智能_Blog" title="人工智能" href="https://developer.huaweicloud.com/tags/102294/blog_1">人工智能</a>
        
    </div>
</div></div>