![Intro to Bash Scripting](https://itnext.io/intro-to-bash-scripting-95c5fbc2dcef)
Intro to Bash Scripting
=======================

Building tools for basic command-line tasks in Bash
---------------------------------------------------

[

![Kenneth Reilly](https://miro.medium.com/fit/c/96/96/2*V96zPRvD_QA14QAS5GkzZw.png)

](/@kennethreilly?source=post_page-----95c5fbc2dcef----------------------)

[Kenneth Reilly](/@kennethreilly?source=post_page-----95c5fbc2dcef----------------------)

Follow

[Sep 3](/intro-to-bash-scripting-95c5fbc2dcef?source=post_page-----95c5fbc2dcef----------------------) · 8 min read

![](https://miro.medium.com/max/60/1*nlte8CxUQ8S3MpN9aA1KmA.png?q=20)

![](https://miro.medium.com/max/3844/1*nlte8CxUQ8S3MpN9aA1KmA.png)

[GNU Bash](https://www.gnu.org/software/bash/)

Introduction
------------

Developing software typically involves spending a lot of time at the command line. Various tasks require the ability to input very detailed instructions to the computer, in ways that are difficult to impossible to accomplish without a text-based interface and a keyboard (and coffee).

In this article we’ll look at the basics of creating useful tools in [Bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)), the most common shell found within server-side architecture and DevOps.

While shell scripting is indeed _scripting,_ an effort is made to apply as many concepts of production-grade software engineering to the example project as possible, to establish best practices that result in a high degree of success (and makes it easier to figure out what happened if something breaks).

A copy of the source code for this article is available [here on GitHub](https://github.com/kenreilly/bash-tools-example).

* * *

Overview
--------

Bash is a [command language](https://en.wikipedia.org/wiki/Command_language) with a syntax derived from natural human language and a feature set that includes command execution, conditional logic, calculations, arrays/dictionaries, iteration/looping, functions, string manipulation, expansion, and more — making it extremely useful for batch processing, job control, maintenance, and other sysadmin tasks.

For a general overview of Bash features and how they work, check out this excellent [cheatsheet](https://devhints.io/bash). Getting started with Bash is easy and requires nothing more than access to a terminal. To create and run a basic script:

**$** echo 'echo "hello $1"' > hello.sh   
**$** chmod +x hello.sh  
**$** ./hello.sh programmerhello programmer

The first line [redirects](https://www.gnu.org/software/bash/manual/html_node/Redirections.html) the literal string `‘echo “hello $1"'` to the file _hello.sh_, and the second line [enables execute permissions](https://en.wikipedia.org/wiki/Chmod) for the script. The third line runs the script with `programmer` as an argument, which is output back to the terminal via the `$1` variable. This illustrates the very basics of what `.sh` files are, and how they can take input and produce output from it. Next, we’ll look at the concept of formatting `.sh` files into structured blocks of code.

* * *

Entry Point
-----------

A bash script is interpreted line-by-line from the top-down, and other bash files can be imported using the `source _my-script-name.sh_`  command, which is useful for organizing various concepts into reusable library code.

Here is the main file in our example project, **bash-example.sh**:

The first line contains`#!/bin/bash` — an interpreter directive scheme called a [shebang](https://en.wikipedia.org/wiki/Shebang_(Unix)), which tells the environment to process the rest of this file using the`bash` interpreter. The line `source ./lib/main.sh` imports the main function into the current session, which is then called with `main $@` which passes all arguments within the current scope (the `@` parameter) to the main function. This file is kept clean as a definition / entry file.

* * *

Main Function
-------------

Next up is the main function for this utility, in **lib/main.sh**:

After the [shebang](https://en.wikipedia.org/wiki/Shebang_(Unix)), the rest of the library scripts are sourced, each of which we will inspect further in a moment. The _main()_ function invoked at the entry point (in the previous file) begins with initializing directories for various data processing tasks handled by this example utility. Next, the command\_table variable is created with the Bash command `declare -A -x command_table` which creates an associative array (`-A`) and allows the variable to be initialized with a value (`-x`). This creates a simple function table to avoid having to use much larger `if/elif` or `switch` blocks. The keys from the `command_table` are then parsed into the simple indexed array `commands` which is used to display help information when called with incorrect arguments.

The first argument taken in from the command line is stored as `command` and then `shift` is called, which then pushes that item off the argument stack. The command is looked up in the command table, and if a matching key exists, the corresponding function is invoked with the remaining argument stack, by calling `$fn_name $@` which takes the value of `fn_name` and executes it as a shell command with parameters being passed in.

There are three features supported by this small Bash program:

*   `scan-files **_num_**  :` scans the current directory for **_num_** largest files, and outputs the result to a log under `./data/logs`
*   `process-logs :` processes log files, writes a summary to `./data/reports`, creates a `tar.gz` file in `./data/archives`, and deletes the log files
*   `get-photo :` gets NASA’s Astronomy Picture of the Day and places the photo `.jpg` along with corresponding `.json` under `./data/images`

We’ll go over each of these functions in a moment, but first let’s check out the underlying configuration and utility functions that are used throughout the rest of this example project.

* * *

Configuration
-------------

No project would be complete without some initial setup and config. The next file we’ll check out is **lib/config.sh**:

First, error handling is set-up by creating a handler function _on\_error(),_ setting error tracing, and then setting an error trap to call _on\_error_ when an `ERR` condition occurs (which provides useful feedback when debugging).

Next, alias expansion is enabled to allow easy expansion and re-use of aliases. This functionality isn’t used much within this project but it’s here just in case.

Another trap is set, this time for the `TERM` signal, to make it easy to exit from the script from any point at any time. Finally, the current working directory is discovered and stored in `_ROOT` for use in filesystem operations, to ensure that the correct directory is used throughout the rest of the codebase.

* * *

Utility Functions
-----------------

The next file up for inspection is **lib/utility.sh**:

Within this file are a few simple utility functions to make life easier when working on this project. The _exit\_with\_help_ function displays a message passed in as an argument, and then exits the script. The _get\_timestamp_ function prints out the result of a `date` command with format string, and _init\_dir_ checks for a directory, and if it doesn’t it exist, creates it.

The _str\_split_ function takes a string as an input, and “returns” an array by setting a global associative array str\_split\_result, which is accessed by the calling script after invoking str\_split. The array is generated by setting the internal Bash read delimiter `IFS` to the value provided, and then reading the string data with `read` (which breaks the string into an array by `IFS`) and storing the result in `str_split_result` to be used later.

* * *

File Scanning
-------------

With the basic config and helper functions out of the way, let’s check out the first feature (file scanning) in **lib/file-io.sh**:

The _write\_file_ function redirects the output of a printf statement to a path built from the root url and the provided string path. The write\_log function just calls _write\_log_ with a `‘logs/’` prefix to store the file under `data/logs`.

The actual scan feature is implemented in _scan\_large\_files_ which first checks to verify that a parameter has been passed in (for number of largest files to log), and if one wasn’t provided, prints a help message and exits.

Next, a `find` command is ran to search for all files within the current directory and below, piped through `awk`,`sort`, and `head` to filter, sort, and extract the top x files from the list. The result of this is stored in `data`, and a `timestamp` is generated. The contents of `data` are then saved to a file.

This completes the file scanner and log generator. There is one more function in this file, `create_archive` (which is called from the next file we’ll check out) that effectively just runs a `tar` to archive and compress the log files, saving the resulting archive to `./data/archives`.

The _create\_report_ function writes the contents of `log_data` to a formatted `.yaml` file for readibility.

* * *

Data Processing
---------------

Next up is the second feature in this example, processing the log files generated by the file scanner, implemented in **lib/log-processor.sh**:

This file is where most of the complex work in this program is done. The first function within the file is _process\_logs,_ which starts by initializing a global associative array `log_data` that will hold the data used to create a report. Another find command is used and the result is stored in `logs`. Counters for total number of files and lines are also initialized. Next, a check is performed and if no log files are available, the script exits.

Each log file is processed as `record`, and the date is extracted by calling `str_split` with an underscore delimiter (`_`) and retrieving the second item from the array. If the date is blank for some reason, the entry is ignored and the script continues processing the next item in the list. Each log file is read into `line` which is then passed into the `process_entry` function for further processing, which we will examine in a moment.

The _process\_entry_ function sets a few local variables, prints some [colorized](https://misc.flogisoft.com/bash/tip_colors_and_formatting) status information, and then looks to see if the file already exists in `log_data`. If so, the dates of the two entries are compared, and if the current item is newer than the one in the array, the older one is replaced. Otherwise, the item is simply added to the array.

Once each record has been processed, some status info is displayed and the script runs `create_report` and `create_archive` to generate a report and archive the log files to their respective locations.

* * *

Image Downloader
----------------

Last but not least, we have the image downloader in **lib/net-client.sh**:

Here we have a function, `get_nasa_photo`, for retrieving information from NASA about their current [Astronomy Picture of the Day](https://apod.nasa.gov/apod/astropix.html). This function begins by defining the NASA URL for this servic, executing a [cURL](https://en.wikipedia.org/wiki/CURL) operation on it, and storing the result in `json`. The `filename` variable is also initialized to an empty string. Next, the json is trimmed of it’s leading and trailing braces using the string expansion range selector `${json:1:-1}` which takes the value of `json` and returns the beginning `+1` through the end `-1`. This is passed into _str\_split_ to split the remaining string by the `','` character, which will not allow for correct parsing of the entire JSON data but will get us one step closer to the only value we need from it, the `url`. This is an example of a pure hack and is done for for the sake of implementing a solution in pure Bash, but for production scenarios a command-line JSON processing tool [such as jt](https://stedolan.github.io/jq/) is recommended instead.

Each section of the split JSON data is processed as `field` and when one that starts with `'"url":'` is found, it’s further processed to retrieve the actual URL from the string. Once the URL is obtained, the filename is retrieved from it and _download\_image_ is called, which executes another `curl` operation to download the file contents and redirect them to the target `.jpg` file.

Once the download is complete, the original unmodified JSON data is also written, with the same filename but with a `.json` extension instead of `.jpg`.

* * *

Conclusion
----------

Bash is a powerful command-line environment that provides developers and system administrators with a wide variety of tools to quickly automate many common tasks, especially when it comes to deployment and maintenance.

This project illustrates just a few things that can be accomplished in Bash. For a more detailed look, check out this [advanced scripting guide](https://www.tldp.org/LDP/abs/html/) or refer back to the [cheatsheet](https://devhints.io/bash) mentioned earlier.

Thanks for reading and good luck with your next DevOps project!

* * *

![](https://miro.medium.com/freeze/max/60/1*Ycl-WVGY_UfDMcT2kc7bnw.gif?q=20)

![](https://miro.medium.com/max/2732/1*Ycl-WVGY_UfDMcT2kc7bnw.gif)

Screen capture of **bash-example.sh** in action

* * *

_Kenneth Reilly (_[_8\_bit\_hacker_](https://twitter.com/8_bit_hacker)_) is the CTO of_ [_The Innovation Group_](https://innovationgroup.tech/)_, an R&D firm that specializes in solving challenging technical problems and assisting others with putting the tools of tomorrow into production today._