![什么是深度学习？](https://towardsdatascience.com/what-is-deep-learning-and-how-does-it-work-f7d02aa9d477)
什么是深度学习以及它如何工作？
===============

坐下来，放松，并熟悉酷炫的概念，如人工神经网络，梯度下降，反向传播等。
-----------------------------------

[

![安妮邦纳](https://miro.medium.com/fit/c/96/96/1*PTe8OwMGSwTvClfzi1rlKQ.jpeg)

](/@annebonner?source=post_page-----f7d02aa9d477----------------------)

[安妮邦纳](/@annebonner?source=post_page-----f7d02aa9d477----------------------)

跟随

[9月8日](/what-is-deep-learning-and-how-does-it-work-f7d02aa9d477?source=post_page-----f7d02aa9d477----------------------) · 13 分钟阅读

![](https://miro.medium.com/max/60/1*L9oKr7Ao8xDCQrYirGc5nA.jpeg?q=20)

![](https://miro.medium.com/max/3705/1*L9oKr7Ao8xDCQrYirGc5nA.jpeg)

![](https://miro.medium.com/max/7410/1*L9oKr7Ao8xDCQrYirGc5nA.jpeg)

照片来自[Pexels](https://www.pexels.com/photo/close-up-of-a-siamese-fighting-fish-325045/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的[Chevanon摄影](https://www.pexels.com/@chevanon?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)[](https://www.pexels.com/photo/close-up-of-a-siamese-fighting-fish-325045/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)

什么是深度学习？
========

它是**从实例中学习的**。这几乎就是这笔交易。

在非常基础的层面上，深度学习是一种机器学习技术。它教授计算机通过层过滤输入，以学习如何预测和分类信息。观察可以是图像，文本或声音的形式。

深度学习的灵感是人类大脑过滤信息的方式。它的目的是模仿人类大脑如何创造一些真正的魔法。

GIF通过[GIPHY](https://media.giphy.com/media/9N2UvCx7wXLnG/200w_d.gif)

_它实际上是一个人工神经网络_。

在人类大脑中，大约有1000亿个神经元。每个神经元连接到大约100,000个邻居。我们正在重新创造它，但在某种程度上和适用于机器的水平。

在我们的大脑中，神经元有一个身体，树突和一个轴突。来自一个神经元的信号沿着轴突传播并转移到下一个神经元的树突。信号通过的那个连接称为突触。

神经元本身就没用了。但是当你拥有很多它们时，它们会共同创造一些严肃的魔力。这就是深度学习算法背后的想法！您可以从观察中获得输入，并将输入放在一个图层中。该层创建一个输出，该输出又成为下一层的输入，依此类推。这种情况反复发生，直到最终输出信号！

神经元（**节点**）获得通过神经元的信号或信号（**输入值**）。那神经元传递**输出信号**。

将输入层视为您的感官：例如，您看到的东西，气味和感觉。这些是一次观察的独立变量。此信息分为数字和计算机可以使用的二进制数据位。您需要对这些变量进行标准化或规范化，以使它们处于相同的范围内。

他们使用多层非线性处理单元进行特征提取和转换。每个连续层使用前一层的输出作为其输入。他们学到的东西构成了概念的层次结构。在此层次结构中，每个级别都学习将其输入数据转换为越来越抽象和复合的表示。

![](https://miro.medium.com/max/60/0*pk2jVyLk2m9sRixz.png?q=20)

![](https://miro.medium.com/max/640/0*pk2jVyLk2m9sRixz.png)

![](https://miro.medium.com/max/1280/0*pk2jVyLk2m9sRixz.png)

图片来自ahmedgad，在[...](http://pixabay.com/)

这意味着对于图像，例如，输入可能是像素矩阵。第一层可能编码边缘并组成像素。下一层可能构成边缘排列。下一层可能编码鼻子和眼睛。下一层可能会识别出图像包含面部，依此类推。

神经元内部会发生什么？
===========

输入节点以数字形式接收信息。该信息表示为激活值，其中每个节点都有一个数字。数字越大，激活越大。

基于连接强度（权重）和传递函数，激活值传递到下一个节点。每个节点对它接收的激活值求和（它计算**加权和**）并根据其传递函数修改该和。接下来，它应用激活功能。激活函数是应用于该特定神经元的函数。由此，神经元理解它是否需要传递信号。

每个突触都获得分配的权重，这对**人工神经网络**（ANN）至关重要。权重是人工神经网络学习的方式。通过调整权重，ANN决定信号传递的程度。当您训练网络时，您正在决定如何调整权重。

激活通过网络运行，直到到达输出节点。输出节点然后以我们可以理解的方式向我们提供信息。您的网络将使用成本函数来比较输出和实际预期输出。模型性能由成本函数评估。它表示为实际值和预测值之间的差异。您可以使用许多不同的成本函数，您正在查看网络中的错误。你正在努力减少损失功能。（实质上，损失函数越低，它与您想要的输出越接近）。信息返回，神经网络开始学习，目的是通过调整权重来最小化成本函数。此过程称为**反向传播**。

在前**向传播中**，信息被输入到输入层并通过网络向前传播以获得我们的输出值。我们将这些值与预期结果进行比较。接下来，我们计算错误并向后传播信息。这允许我们训练网络并更新权重。（反向传播允许我们同时调整所有权重。）在此过程中，由于算法的结构方式，您可以同时调整所有权重。这允许您查看神经网络中每个权重的错误部分。

当您将重量调整到最佳水平时，您就可以进入测试阶段了！

![](https://miro.medium.com/max/60/1*QC88xWhhRqpW7qM-bIsRKg.jpeg?q=20)

![](https://miro.medium.com/max/3409/1*QC88xWhhRqpW7qM-bIsRKg.jpeg)

![](https://miro.medium.com/max/6818/1*QC88xWhhRqpW7qM-bIsRKg.jpeg)

照片来自[Pexels](https://www.pexels.com/photo/photo-of-jumping-man-1701203/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的[Yogendra Singh](https://www.pexels.com/@yogendras31?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)[](https://www.pexels.com/photo/photo-of-jumping-man-1701203/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)

How does an artificial neural network learn?
============================================

There are two different approaches to get a program to do what you want. First, there’s the specifically guided and hard-programmed approach. You tell the program exactly what you want it to do. Then there are **neural networks**. In neural networks, you tell your network the inputs and what you want for the outputs, and then you let it learn on its own.

By allowing the network to learn on its own, you can avoid the necessity of entering in all of the rules. You can create the architecture and then let it go and learn. Once it’s trained up, you can give it a new image and it will be able to distinguish output.

Feedforward and feedback networks
=================================

A **feedforward** network is a network that contains inputs, outputs, and hidden layers. The signals can only travel in one direction (forward). Input data passes into a layer where calculations are performed. Each processing element computes based upon the weighted sum of its inputs. The new values become the new input values that feed the next layer (feed-forward). This continues through all the layers and determines the output. Feedforward networks are often used in, for example, data mining.

A **feedback network** (for example, a recurrent neural network) has feedback paths. This means that they can have signals traveling in both directions using loops. All possible connections between neurons are allowed. Since loops are present in this type of network, it becomes a non-linear dynamic system which changes continuously until it reaches a state of equilibrium. Feedback networks are often used in optimization problems where the network looks for the best arrangement of interconnected factors.

What is a weighted sum?
=======================

Inputs to a neuron can either be features from a training set or outputs from the neurons of a previous layer. Each connection between two neurons has a unique synapse with a unique weight attached. If you want to get from one neuron to the next, you have to travel along the synapse and pay the “toll” (weight). The neuron then applies an activation function to the sum of the weighted inputs from each incoming synapse. It passes the result on to all the neurons in the next layer. When we talk about updating weights in a network, we’re talking about adjusting the weights on these synapses.

A neuron’s input is the sum of weighted outputs from all the neurons in the previous layer. Each input is multiplied by the weight associated with the synapse connecting the input to the current neuron. If there are 3 inputs or neurons in the previous layer, each neuron in the current layer will have 3 distinct weights: one for each synapse.

In a nutshell, the activation function of a node defines the output of that node.

激活功能（或传递函数）将输入信号转换为输出信号。它将输出值映射到0到1或-1到1的范围。它是一个抽象，表示在单元格中触发的动作速率。它是一个数字，代表细胞发射的可能性。最简单的是，函数是二进制：**是**（神经元激发）或**否**（神经元不激发）。输出可以是0或1（开/关或是/否），也可以是范围内的任何位置。例如，如果您使用的函数映射0到1之间的范围以确定图像是猫的可能性，则输出0.9将显示您的图像实际上是猫的概率为90％。

**什么是激活功能？**
============

简而言之，节点的激活功能定义了该节点的输出。

激活功能（或传递函数）将输入信号转换为输出信号。它将输出值映射到0到1或-1到1的范围。它是一个抽象，表示在单元格中触发的动作速率。它是一个数字，代表细胞发射的可能性。最简单的是，函数是二进制：**是**（神经元激发）或**否**（神经元不激发）。输出可以是0或1（开/关或是/否），也可以是范围内的任何位置。

我们有什么选择？有许多激活功能，但这些是非常常见的四种：

**阈值功能**
========

这是一个阶梯函数。如果输入的总和值达到某个阈值，则函数传递0.如果它等于或大于零，则它将传递1.它是一个非常严格，直接，是或否的函数。

![](https://miro.medium.com/max/60/0*LLWTicPcC3T1X9X5.png?q=20)

![](https://miro.medium.com/max/288/0*LLWTicPcC3T1X9X5.png)

![](https://miro.medium.com/max/576/0*LLWTicPcC3T1X9X5.png)

示例阈值函数

**Sigmoid功能**
=============

此函数用于逻辑回归。与阈值函数不同，它是从0到1的平滑渐进过程。它在输出层非常有用，并且大量用于线性回归。

![](https://miro.medium.com/max/60/0*NHsOkUbb8c9V06ZQ.png?q=20)

![](https://miro.medium.com/max/288/0*NHsOkUbb8c9V06ZQ.png)

![](https://miro.medium.com/max/576/0*NHsOkUbb8c9V06ZQ.png)

示例S形函数

**双曲正切函数**
==========

此函数与sigmoid函数非常相似。但是不同于从0到1的sigmoid函数，该值低于零，从-1到1.尽管这与大脑中发生的情况不太相似，但这个函数在训练神经元时会产生更好的结果网络。在使用S形函数训练期间，神经网络有时会“卡住”。当有很多强负输入使输出接近零时会发生这种情况，这与学习过程混淆。

![](https://miro.medium.com/max/60/0*5MFqcP1Qdn6htYAC.png?q=20)

![](https://miro.medium.com/max/288/0*5MFqcP1Qdn6htYAC.png)

![](https://miro.medium.com/max/576/0*5MFqcP1Qdn6htYAC.png)

双曲正切函数示例（tanh）

**整流功能**
========

这可能是神经网络领域最受欢迎的激活函数。它是最有效和生物学合理的。即使它有一个扭结，它在扭结为0之后也是平滑和渐进的。这意味着，例如，你的输出将是“否”或“是”的百分比。这个功能不需要标准化或其他复杂的计算。

![](https://miro.medium.com/max/60/0*6h-5AslRa-oWwAie.png?q=20)

![](https://miro.medium.com/max/288/0*6h-5AslRa-oWwAie.png)

![](https://miro.medium.com/max/576/0*6h-5AslRa-oWwAie.png)

示例整流器功能

什么？
===

例如，假设您所需的值是二进制的。您正在寻找“是”或“否”。您想使用哪种激活功能？

从上面的例子中，你可以使用阈值函数，或者你可以使用sigmoid激活函数。阈值函数会给你一个“是”或“否”（1或0）。sigmoid函数可以给你一个是的概率。

例如，如果您使用sigmoid函数来确定图像是猫的可能性，那么0.9的输出将显示您的图像实际上是猫的概率为90％。

![](https://miro.medium.com/max/60/0*0g4Clzsw03sQLHI6.jpeg?q=20)

![](https://miro.medium.com/max/640/0*0g4Clzsw03sQLHI6.jpeg)

![](https://miro.medium.com/max/1280/0*0g4Clzsw03sQLHI6.jpeg)

照片由minanafotos，[如下](https://pixabay.com/)

想进一步了解图像分类？看看这篇文章吧！

[

完整初学者深度学习指南：卷积神经网络


----------------------

### 

在几分钟内征服CNN的基础知识和图像分类

#### 

towardsdatascience.com



](/wtf-is-image-classification-8e78a8235acb?source=post_page-----f7d02aa9d477----------------------)

想深入了解？查看Xavier Glorot等人的[Deep Sparse Rectifier Neural Networks](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf)。

你如何调整重量？
========

您可以使用蛮力方法来调整权重并测试数千种不同的组合。但即使最简单的神经网络只有五个输入值和一个隐藏层，你最终可能会有10个可能的组合。

在这个世界上最快的超级计算机上运行它需要比宇宙迄今为止所用的时间更长的时间。

输入梯度下降
======

但是如果你使用**渐变下降**，你可以查看权重斜率的角度，并找出它是正还是负，以便继续下坡，找到最佳权重，以达到全局最小值。

如果你使用**渐变下降**，你可以查看权重斜率的角度，并找出它是正还是负。这使您可以继续下坡，找到最佳的权重，以达到全局最小值。

![](https://miro.medium.com/max/48/1*IOaN68A9G9-ReSjZBQ_LZw.jpeg?q=20)

![](https://miro.medium.com/max/3000/1*IOaN68A9G9-ReSjZBQ_LZw.jpeg)

![](https://miro.medium.com/max/6000/1*IOaN68A9G9-ReSjZBQ_LZw.jpeg)

照片来自[Pexels](https://www.pexels.com/photo/man-sitting-on-a-mountain-cliff-2402891/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的[RANJAN](https://www.pexels.com/@ranjan-simkhada-1263037?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels) [SIMKHADA](https://www.pexels.com/photo/man-sitting-on-a-mountain-cliff-2402891/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)

**梯度下降**是用于找到函数的最小值的算法。你会一遍又一遍地看到的类比是那些被困在山顶并试图下山的人（找到最小值）。大雾使得无法看到路径，因此她使用梯度下降来到山的底部。她看着她所在山丘的陡峭程度，向最陡峭的方向前进。你应该假设陡峭度不是很明显。幸运的是，她有一个可以测量陡度的工具！

不幸的是，这个工具需要永远。

她想尽可能少地使用它，因为她可以在天黑之前下山。真正的困难在于选择她想要使用她的工具的频率，这样她就不会偏离轨道。

在这个比喻中，人就是算法。山的陡度是该点处误差表面的斜率。她走的方向是那一点的误差表面的梯度。她使用的工具是微分（误差曲面的斜率可以通过在该点取平方误差函数的导数来计算）。她在进行另一次测量之前行进的速率是算法的学习率。这不是一个完美的类比，但它让你很好地了解梯度下降的全部意义。机器正在学习模型应采取的梯度或方向，以减少错误。

![](https://miro.medium.com/max/60/1*rAjDOcrraaX7aq7iJsvMXw.png?q=20)

![](https://miro.medium.com/max/407/1*rAjDOcrraaX7aq7iJsvMXw.png)

![](https://miro.medium.com/max/814/1*rAjDOcrraaX7aq7iJsvMXw.png)

梯度下降（简化！）

梯度下降要求成本函数是凸的，但**如果不是**？

![](https://miro.medium.com/max/60/1*nljI2gSabTp8IFWr9__LFQ.png?q=20)

![](https://miro.medium.com/max/596/1*nljI2gSabTp8IFWr9__LFQ.png)

![](https://miro.medium.com/max/1192/1*nljI2gSabTp8IFWr9__LFQ.png)

怎么办？

正常梯度下降将陷入局部最小值而不是全局最小值，从而导致低于一般的网络。在正常的梯度下降中，我们将所有行并将它们插入到相同的神经网络中，查看权重，然后调整它们。这称为批量梯度下降。在随机梯度下降中，我们逐行获取行，运行神经网络，查看成本函数，调整权重，然后移动到下一行。基本上，您正在调整每行的权重。

**随机梯度下降**具有更高的波动，这使您可以找到全局最小值。它被称为“随机”，因为样本是随机混洗的，而不是单个组或它们出现在训练集中。看起来它可能更慢，但它实际上更快，因为它不必将所有数据加载到内存中并等待数据全部一起运行。批量梯度下降的主要原因是它是一种确定性算法。这意味着如果您具有相同的起始权重，则每次运行网络时都会得到相同的结果。随机梯度下降总是随机工作。（您还可以在设置多行的情况下运行小批量梯度下降，一次运行多行，然后更新权重。）

已经提出并使用了基本随机梯度下降算法的许多改进，包括隐式更新（ISGD），动量方法，平均随机梯度下降，自适应梯度算法（AdaGrad），均方根传播（RMSProp），自适应矩估计（Adam） ）， 和更多。

因此，这是一个训练具有随机梯度下降的人工神经网络的快速演练：

*   随机启动权重到接近0的小数
*   将数据集的第一次观察输入到输入层，每个特征都在一个输入节点中。
*   **向前传播** - 从左到右，神经元被激活，每个神经元的激活都受到权重的限制。您传播激活直到获得预测结果。
*   将预测结果与实际结果进行比较并测量生成的误差。
*   **反向传播** - 从右到左，错误被反向传播。权重根据它们对错误负责的程度进行更新。（学习率决定我们更新权重的程度。）
*   **强化学习**（重复步骤1-5并在每次观察后更新权重）**或** **批量学习**（重复步骤1-5，但仅在一批观察后更新权重）。
*   当整个训练集通过人工神经网络时，就是一个时代。重复更多的纪元。

你有它！这些是人工神经网络中发生的事情背后的基本思想。
---------------------------

想了解更多？

您可能希望阅读Yann LeCun等人的[Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)，以及Michael Nielsen的[神经网络和深度学习](http://neuralnetworksanddeeplearning.com/)。如果您有兴趣了解有关成本函数的更多信息，请查看[神经网络中使用的成本函数列表以及应用程序](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)。

谢谢阅读！如果您有任何疑问，请在下面的评论中告诉我们，或[随时与我们联系](https://contentsimplicity.com/articles/)！

* * *

_最初于__2019年9月7日__在_[_Content Simplicity_](https://contentsimplicity.com/what-is-deep-learning-and-how-does-it-work/)_上__发布__。_