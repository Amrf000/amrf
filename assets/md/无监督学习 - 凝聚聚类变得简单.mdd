![无监督学习 - 凝聚聚类变得简单](https://medium.com/@surajramesh6292/unsupervised-learning-agglomerative-clustering-made-simple-102ddfcbd0cf)
无监督学习 - **凝聚**聚类变得简单
====================

[![SurajPR](https://miro.medium.com/fit/c/48/48/0*iJuZ-oXpBbyfxTjl.)](/@surajramesh6292?source=post_page-----102ddfcbd0cf----------------------)

[SurajPR](/@surajramesh6292?source=post_page-----102ddfcbd0cf----------------------)

跟随

[7月6日](/@surajramesh6292/unsupervised-learning-agglomerative-clustering-made-simple-102ddfcbd0cf?source=post_page-----102ddfcbd0cf----------------------) · 9 分钟阅读

大熊猫是否更接近熊或浣熊？

Netflix列出了您感兴趣的电影，它是如何知道的？

![](https://miro.medium.com/max/30/1*qaGa5vgVkGYq8PTw19D_Jw.png?q=20)

![](https://miro.medium.com/max/621/1*qaGa5vgVkGYq8PTw19D_Jw.png)

图1：我属于浣熊还是熊家？

许多这样的问题可以通过**聚类**来回答。如果给定的数据集上没有类标签，我们可以利用无监督学习算法来获得数据模式的见解。

一种这样的无监督学习技术是聚类。

在语言学上，集群意味着一组被组合在一起的类似事物，机器学习也没有什么不同，它还将集群定义为将类似数据点组合在一起的技术。

一些最常用的聚类算法是

1.  凝聚层次聚类
2.  K-Means聚类
3.  分裂的分层聚类
4.  DBSCAN

让我们更详细地讨论分层聚类。它是一种聚类分析方法，旨在构建聚类层次结构。层次聚类策略分为两类

**分裂**

我们首先假设所有数据点都是一个集群的一部分，并在每次迭代时将集群划分为两个集群。

**凝聚**

凝聚聚类首先  假设每个数据点是一个单独的聚类，并在每次迭代时组合一对聚类，以形成一个包含所有数据点的单个大聚类。

让我们详细讨论凝聚聚类

基本算法很简单

1.  计算邻近矩阵
2.  让每个数据点成为一个集群
3.  循环重复a和b，直到只剩下单个簇

a.Merge两个最接近的集群

b。更新邻近矩阵

**邻近矩阵**只是一个距离矩阵，它定义了数据点之间的距离，如下所示。我们刚刚定义了非对角元素，因为对角线两侧的值意味着相同。矩阵的列和行都是数据点，矩阵**A\_ij的**每个单元将定义相应数据点**i**和**j**之间的距离。

因此，假设使用的距离度量将是欧几里德距离。点P和Q之间的距离定义为

d（P，Q）= SquareRoot（（q1-p1）²+（q2-p2）²+ ......... +（qd-pd）²），其中P和Q是d维向量。

为简单起见，我们将点P1，P2，P3，P4，P5和P6作为二维空间中的数据点。

![](https://miro.medium.com/max/30/1*4_ufe7CzAMN5gzhHnhQ0Fg.png?q=20)

![](https://miro.medium.com/max/314/1*4_ufe7CzAMN5gzhHnhQ0Fg.png)

图2：数据点的X和Y坐标

![](https://miro.medium.com/max/30/1*66vJP_ZWtppQ6rgyqOt8sw.png?q=20)

![](https://miro.medium.com/max/288/1*66vJP_ZWtppQ6rgyqOt8sw.png)

图3：二维平面上数据点的简单图

让我们准备一个基本的邻近矩阵，它显示所有点Pi和Pj之间的距离，其中i，j在我们的例子中从1到6。

欧氏距离（P1，P6）= SqRoot（（0.44-0.22）²+（0.53-0.38）²）= 0.23

![](https://miro.medium.com/max/30/1*is4cXBUAWLWFP9EuWg-cWw.png?q=20)

![](https://miro.medium.com/max/391/1*is4cXBUAWLWFP9EuWg-cWw.png)

图4：基本接近矩阵

以下是我们读取此矩阵的方法，突出显示的单元格A\_ij 0.11将表示点P3和P6之间的距离。

定义两点之间的距离非常简单，但问题是我们如何定义两个点之间的距离？

![](https://miro.medium.com/max/30/1*cHoIwLk-3YZOxPdib8rsNw.png?q=20)

![](https://miro.medium.com/max/494/1*cHoIwLk-3YZOxPdib8rsNw.png)

图5：两个集群之间的距离

定义簇之间距离的最常用方法是

> 最小/单链接
> 
> 最大/完整链接
> 
> 组平均/平均链接
> 
> 沃德的方法

**单连杆/分钟**

这是两个群集中最近成员之间的距离。

![](https://miro.medium.com/max/30/1*kzRGZEg1a4WlAVcwWRWMag.png?q=20)

![](https://miro.medium.com/max/391/1*kzRGZEg1a4WlAVcwWRWMag.png)

简单的链接

让我们一步一步......

如上图2所示，我们有六个点P1到P6。现在我们的任务是将这六个点分组。从基本的邻近矩阵（图4），注意到0.11是最小的值，它表明P3-P6之间的距离是0.11，这是其他群集中最少的（不要忘记，我们最初的假设是每个数据点是一个簇）。由于距离最短，因此意味着它们最相似。现在将P3-P6组合成一个单独的集群。

![](https://miro.medium.com/max/30/1*pRSlcWpmy4hcZ8W5EWEktg.png?q=20)

![](https://miro.medium.com/max/288/1*pRSlcWpmy4hcZ8W5EWEktg.png)

现在重新计算邻近矩阵。

dist（（P3，P6），P1）= Min（dist（P3，P1），dist（P6，P1））= Min（0.22,0.23）

dist（（P3，P6），P1）= 0.22，这是点P1和包括P3和P6的簇之间的距离。

类似地，找到簇P3-P6与点P2，P4和P5之间的距离。

更新邻近矩阵的单元格，如下所示

![](https://miro.medium.com/max/30/1*cgGWY_9eUtkJpJZoll2FtQ.png?q=20)

![](https://miro.medium.com/max/311/1*cgGWY_9eUtkJpJZoll2FtQ.png)

现在注意到0.14是最小的值，它告诉P2-P5是最近的点，并让它们分组到一个簇中。

![](https://miro.medium.com/max/30/1*67pK7w6hcIW79g3hr8X2UQ.png?q=20)

![](https://miro.medium.com/max/288/1*67pK7w6hcIW79g3hr8X2UQ.png)

现在重新计算邻近矩阵。

dist（（P2，P5），P1）= Min（dist（P2，P1），dist（P5，P1））= Min（0.23,0.34）

dist（（P2，P5），P1）= 0.23，这是点P1和包括P2和P5的簇之间的距离。

dist（（P2，P5），（P3，P6））= Min（dist（P2，（P3，P6）），dist（P5，（P3，P6）））= Min（0.15,0.28）= 0.15，这个是簇P3-P6和P2-P5之间的距离。

类似地，找到簇P2-P5和点P4之间的距离。

更新邻近矩阵的单元格，如下所示

![](https://miro.medium.com/max/30/1*x-BKZB4KQxL84_NPiwetvg.png?q=20)

![](https://miro.medium.com/max/312/1*x-BKZB4KQxL84_NPiwetvg.png)

从上面的矩阵注意到，0.15是表示簇P3-P6和P2-P5最接近的最小值。所以将它们分组到一个集群中。

![](https://miro.medium.com/max/30/1*ibY0ePwHmxlO0fLDQzcVcg.png?q=20)

![](https://miro.medium.com/max/288/1*ibY0ePwHmxlO0fLDQzcVcg.png)

现在找到簇P1和P4之间的簇P2-P5-P3-P6之间的距离。

dist（（（P2，P5），（P3，P6）），P4）=

Min \[dist（（P2，P5），（P4）），dist（（P2，P5），P4））\] = Min \[0.20,0.15\] = 0.15

这是簇P2-P5-P3-P6和P4之间的距离。

更新的邻近矩阵如下所示

![](https://miro.medium.com/max/30/1*ew7w08YyV4pIuQModntzNg.png?q=20)

![](https://miro.medium.com/max/368/1*ew7w08YyV4pIuQModntzNg.png)

根据上述矩阵通知，0.15是表示簇P4和P2-P5-P3-P6最接近的最小值。所以将它们分组到一个集群中。

![](https://miro.medium.com/max/30/1*H7EQmNDOgLDeFeEgAZ1EcQ.png?q=20)

![](https://miro.medium.com/max/357/1*H7EQmNDOgLDeFeEgAZ1EcQ.png)

**完整链接/最大值：**

这是两个星团中最远的成员之间的距离。

![](https://miro.medium.com/max/30/1*w5W3WtK8o104gXg_3EHANQ.png?q=20)

![](https://miro.medium.com/max/384/1*w5W3WtK8o104gXg_3EHANQ.png)

完整的链接

我们需要深入研究Min和Max的定义，因为它是我们大多数人混淆的地方。我们永远不应忘记，聚类的目的是将相似的数据点组合在一起。最相似的点是那些具有最小距离的点。这里Max将告诉找到两个簇之间距离的方法，并不意味着将它们之间具有Max距离的数据点组合成一个簇。

既然我们已经理解了简单链接的流程，那么我们也可以尝试对Complete Linkage进行相同的操作。

从如图4所示的基本接近矩阵开始，P3-P6之间的距离最小，因此我们将它们分组为一个簇。

![](https://miro.medium.com/max/30/1*pRSlcWpmy4hcZ8W5EWEktg.png?q=20)

![](https://miro.medium.com/max/288/1*pRSlcWpmy4hcZ8W5EWEktg.png)

现在重新计算邻近矩阵。

dist（（P3，P6），P1）= Max（dist（P3，P1），dist（P6，P1））= Max（0.22,0.23）

dist（（P3，P6），P1）= 0.23 =这是簇P1和簇之间的完整连接距离，包括数据点P3-P6。

注意：使用Simple Linkage时，我们将簇P3-P6和P1之间的距离计算为0.22，但完全连接时计算的距离为0.23。

类似地，找到簇P3-P6与P2，P4和P5之间的完整连接距离。

![](https://miro.medium.com/max/30/1*e5XxRIpa9bpVQUr_Zd450g.png?q=20)

![](https://miro.medium.com/max/377/1*e5XxRIpa9bpVQUr_Zd450g.png)

更新的邻近矩阵

现在注意到0.14是最小的值，它告诉P2-P5是最近的点，并让它们分组到一个簇中。

![](https://miro.medium.com/max/30/1*67pK7w6hcIW79g3hr8X2UQ.png?q=20)

![](https://miro.medium.com/max/288/1*67pK7w6hcIW79g3hr8X2UQ.png)

在重新计算邻近矩阵之前，让我们试着找出下一个没有数学计算的集群

![](https://miro.medium.com/max/30/1*PBlLG14V0w5v3JwhFfdd2A.png?q=20)

![](https://miro.medium.com/max/342/1*PBlLG14V0w5v3JwhFfdd2A.png)

d1：簇P2-P5和P3-P6之间的完整连接距离

d2：簇P1和P3-P6之间的完整链接距离

d3：簇P4和P3-P6之间的完整连接距离

您可以观察到d3 <d2 <d1，因为d3最小，我们将P4和P3-P6分组为一个簇。让我们通过使用我们的计算方法证实这一点，

dist（（P2，P5），P1）= Max（dist（P2，P1），dist（P5，P1））= Max（0.23,0.34）

dist（（P2，P5），P1）= 0.34，这是点P1和包括P2和P5的簇之间的距离。

dist（（P2，P5），（P3，P6））= Max（dist（P2，（P3，P6）），dist（P5，（P3，P6）））= Max（0.15,0.28）= 0.28，这个是簇P3-P6和P2-P5之间的完整连接距离。

类似地，找到簇P2-P5和点P4之间的距离。

更新邻近矩阵的单元格，如下所示

![](https://miro.medium.com/max/30/1*SdPU2ZIaR_z9-V_TW66JbQ.png?q=20)

![](https://miro.medium.com/max/342/1*SdPU2ZIaR_z9-V_TW66JbQ.png)

更新的邻近矩阵

从上面的矩阵注意到，0.23是表示簇P3-P6和P4最接近的最小值。所以将它们分组到一个集群中。

![](https://miro.medium.com/max/30/1*2orMR8l1ZRjza5u_7SIoWA.png?q=20)

![](https://miro.medium.com/max/342/1*2orMR8l1ZRjza5u_7SIoWA.png)

现在我们的任务是计算P3-P6-P4与P2-P5和P1之间的距离。

![](https://miro.medium.com/max/30/1*PBQyJmac40cEzxHeKYsmDg.png?q=20)

![](https://miro.medium.com/max/346/1*PBQyJmac40cEzxHeKYsmDg.png)

重新计算的邻近矩阵

请注意，0.34是最小值组P2-P5，P1为一个单独的簇。最后，我们最终得到一个集群，如下所示。

![](https://miro.medium.com/max/30/1*DlRXnZhRpDSpngpb1YGvDA.png?q=20)

![](https://miro.medium.com/max/387/1*DlRXnZhRpDSpngpb1YGvDA.png)

完整的链接聚类

**组平均/平均链接**

该方法涉及查看所有对之间的距离和所有这些距离的平均值

![](https://miro.medium.com/max/30/1*zvEllWNVEt6T7VO8VJHGDQ.png?q=20)

![](https://miro.medium.com/max/521/1*zvEllWNVEt6T7VO8VJHGDQ.png)

用于计算簇之间距离的公式

注意：| cluster\_i | 指定cluster\_i中的数据点数

使用上面的公式使用相同的方法来查找群集。

![](https://miro.medium.com/max/30/1*5k-WUjKV0wG3ijrk05g0Cw.png?q=20)

![](https://miro.medium.com/max/746/1*5k-WUjKV0wG3ijrk05g0Cw.png)

**沃德的方法**

这是Ward于1963年引入的一种特殊类型的凝聚层次聚类技术。

与其他聚类方法一样，Ward的方法以_n个_簇开始，每个簇包含一个对象。将这_n个_簇组合在一起以形成包含所有对象的一个​​簇。在每个步骤中，该过程创建一个新的聚类，最小化方差，由一个名为_E_的索引（也称为平方和_索引_）测量。

在每个步骤中，进行以下计算以找到_E_：

1.  找出每个群集的平均值。
2.  计算特定群集中每个对象与该群集的平均值之间的距离。
3.  平衡与步骤2的差异。
4.  求和（加总）步骤3中的平方值。
5.  将步骤4中的所有平方加起来。

为了在每个步骤中选择新的簇，必须考虑每个可能的簇组合。

![](https://miro.medium.com/max/30/1*TlEKQxG19ZBGJHBrLJwpFw.png?q=20)

![](https://miro.medium.com/max/721/1*TlEKQxG19ZBGJHBrLJwpFw.png)

所有方法之间的比较

现在我们已经了解了不同类型的凝聚聚类。但是，让我们讨论一下何时使用？要回答这个问题，我们可以了解每种技术的优缺点。

**优势：**

基于Min的方法可以非常好地处理非椭圆形状。

![](https://miro.medium.com/max/30/1*exhBirGcrWnEIpvfiKiF5g.png?q=20)

![](https://miro.medium.com/max/736/1*exhBirGcrWnEIpvfiKiF5g.png)

基于Max的方法不易受噪声和异常值的影响。

Ward的方法可用于初始化K-means。

**限制：**

基于最小值的方法对噪声更敏感，并产生长而细长的簇。

基于Max的方法往往具有相同的直径 - 小簇与较大的簇合并。

![](https://miro.medium.com/max/30/1*qPkROBug2KhtITssE75B_A.png?q=20)

![](https://miro.medium.com/max/754/1*qPkROBug2KhtITssE75B_A.png)

假设在聚类的初始阶段，我们有簇Q和R. d1是簇P和R之间的簇间完整链接距离，同样d2是P和Q之间的簇间距离。由于d1> d2，基于Max的方法组P进入簇Q而不是群集R.这是在右图中可以观察到的。

快乐学习......

**参考文献：**

1.  西密歇根大学Ala Al-Fukaha的讲义。
2.  应用AI的Satish Verma讲义。
3.  维基百科。
4.  [https://www.statisticshowto.datasciencecentral.com/wards-method/](https://www.statisticshowto.datasciencecentral.com/wards-method/)。