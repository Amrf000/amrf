原文:![打赌你无法解决这个谷歌面试问题](https://medium.com/free-code-camp/bet-you-cant-solve-this-google-interview-question-4a6e5a4dc8ee)
打赌你无法解决这个谷歌面试问题。
================

将棘手的问题分解成小块。
------------

[![凯文加迪尼](https://miro.medium.com/fit/c/48/48/1*KKkffE-4Vl34Fe29KJWUcw.jpeg)](/@Sawtaytoes?source=post_page-----4a6e5a4dc8ee----------------------)

[凯文加迪尼](/@Sawtaytoes?source=post_page-----4a6e5a4dc8ee----------------------)

跟随

[4月29日](/free-code-camp/bet-you-cant-solve-this-google-interview-question-4a6e5a4dc8ee?source=post_page-----4a6e5a4dc8ee----------------------) · 15 分钟阅读

_我想看到其他人对软件工程的看法，并开始在YouTube上狂热地观看TechLead。接下来的几天，我在谷歌工作时提出的一个面试问题提出了各种解决方案。_

这个视频让我兴奋
========

通过TechLead模拟谷歌面试（软件工程师的工作）

TechLead **在** **Google的****100多次采访中**提出了一个**问题**。让我好奇想在RxJS中想出一个解决方案。本文将讨论传统方法。

他的问题的真正目标是从受访者那里获取信息。他们会在编码前问正确的问题吗？该解决方案是否符合项目准则？他甚至指出，如果你得到正确答案，那根本不重要。他想弄清楚你的想法，以及你是否能够理解这个问题。

他谈到了一些解决方案，一个是递归的（受堆栈大小限制），另一个是迭代的（受内存大小限制）。我们将研究这两个以及更多！

TechLead的问题
===========

在他的问题中，他要求我们采用这个项目网格，并获得所有颜色相同的最大连续块的计数。

![](https://miro.medium.com/max/30/1*uake3YsUeGzRiPGEt3RuSA.png?q=20)

![](https://miro.medium.com/max/2006/1*uake3YsUeGzRiPGEt3RuSA.png)

![](https://miro.medium.com/max/30/1*WmODExHDGW4i23Cwg6-27Q.png?q=20)

![](https://miro.medium.com/max/2002/1*WmODExHDGW4i23Cwg6-27Q.png)

当我听到他的问题并看到图片时，我在想“哦，伙计，我必须做一些2D图像建模才能弄明白”。在采访中听起来几乎不可能回答。

但在他解释得更多之后，事实并非如此。您正在处理已捕获的数据，而不是解析图像。我现在意识到，这个形象实际上是用词不当。

数据建模
====

在编写任何代码之前，您需要定义数据模型。_我不能强调这一点。_在编写任何此类高级代码之前，首先要弄清楚您正在使用的内容并收集业务需求。

在我们的案例中，TechLead为我们定义了很多这些要求：

*   我们称之为彩色方块或“节点”的概念。
*   我们的数据集中有10K个节点。
*   节点被组织成列和行（2D）。
*   列数和行数可能不均匀。
*   节点有颜色和某种方式来表示邻接。

我们还可以从我们的数据中获得更多信息：

*   没有两个节点会重叠。
*   节点永远不会与自己相邻。
*   节点永远不会有重复的邻接关系。
*   位于侧面和角落的节点将分别缺少一个或两个邻接。

我们不知道的是：

*   行与列的比率
*   可能的颜色数量。
*   只有一种颜色的机会。
*   粗糙的颜色分布。

您作为开发人员的级别越高，您就会知道的问题越多。这也不是经验问题。虽然这有帮助，但如果你不能挑出未知数，它就不会让你变得更好。

我不指望大多数人会发现这些未知数。在我开始研究算法之前，我也不知道它们。未知数需要时间来弄明白。这是一个很多的讨论，并与商界人士来回寻找所有的纠结。

看着他的形象，似乎分布是随机的。他只用了3种颜色，从来没有说过什么，所以我们也会这样做。我们还假设所有颜色都可能是相同的。

由于它可以杀死我们的算法，我将假设我们正在使用100x100网格。这样，我们就不必处​​理1行和10K列的奇怪情况。

在典型的设置中，我会在数据发现的前几个小时内询问所有这些问题。这就是TechLead真正关心的。你会从编码随机解决方案开始，还是要找出问题所在？

你将在你的数据模型中犯错误。我知道我在第一次写这篇文章时做过，但如果你提前计划，这些问题将更容易管理。因为它，我最终只需要重写代码的一小部分。

创建数据模型
======

我们需要知道数据是如何进入的以及我们想要处理它的格式。

由于我们没有适当的系统来处理数据，我们需要自己提供可视化。

我们数据的基本构建块：

*   颜色
*   ID
*   X
*   ÿ

我们为什么需要身份证？因为我们可以不止一次地遇到同一个项目。我们想要防止无限循环，所以我们需要标记我们在这些情况下的位置。

此外，通常会为此类数据分配某种ID，哈希值或其他值。它是一个唯一的标识符，因此我们可以通过某种方式识别该特定节点。如果我们想知道最大的连续块，我们需要知道该块中的哪些节点。

由于他在网格中对数据进行了整形，我将假设我们将使用X和Y值来获取数据。使用这些属性，我能够生成一些HTML，以确保我们生成的内容看起来像他给我们的东西。

这是使用绝对定位完成的，就像他的例子一样：

![](https://miro.medium.com/max/30/1*waDXrVIZHjYIHAEVWin54w.png?q=20)

![](https://miro.medium.com/max/400/1*waDXrVIZHjYIHAEVWin54w.png)

答案：3

它甚至适用于更大的数据集：

![](https://miro.medium.com/max/30/1*9vrgCN2D53GLsxAHB_Xx4Q.png?q=20)

![](https://miro.medium.com/max/1001/1*9vrgCN2D53GLsxAHB_Xx4Q.png)

答案：18

他是生成节点的代码：

我们获取列和行，从项目数中创建一维数组，然后从该数据生成我们的节点。

而不是`color`，我正在使用`colorId`。首先，因为随机化更清洁。其次，我们通常必须自己查找颜色值。

虽然他从未明确说过，但他只使用了3种颜色值。我将数据集限制为3种颜色。只知道它可能是数百种颜色，最终的算法不需要改变。

作为一个更简单的例子，这是一个2x2节点列表：

数据处理
====

无论我们将使用哪种方法，我们都想知道每个节点的邻接关系。X和Y值不会削减它。

因此，给定X和Y，我们需要弄清楚如何找到相邻的X和Y值。这很简单。我们只是在X和Y上找到节点加减1。

我为这段逻辑编写了一个辅助函数：

我们生成节点的方式实际上是一种数学方法来计算相邻节点的ID。相反，我将假设节点将以随机顺序进入我们的系统。

我通过第二遍传递所有节点以添加邻接：

我避免在这个预处理器代码中进行任何不必要的优化。它不会影响我们的最终性能统计数据，只会有助于简化我们的算法。

我继续前进，改成了`colorId`一个`color`。这对我们的算法来说完全没必要，但我想让它更容易可视化。

我们呼吁`getNodeAtLocation`每个组相邻的X和Y值，并找到我们的`northId`，`eastId`，`southId`，和`westId`。我们不会传递我们的X和Y值，因为它们不再需要。

获取我们的基本ID后，我们将它们转换为单个`adjacentIds`数组，其中仅包含具有值的数组。这样，如果我们有角和边，我们不必担心检查这些ID是否为空。它还允许我们循环数组而不是手动记录我们的算法中的每个基数ID。

这是使用一组新节点运行的另一个2x2示例`addAdjacencies`：

预处理优化
=====

我想大大简化本文的算法，所以我添加了另一个优化过程。这个删除与当前节点的颜色不匹配的相邻ID。

重写我们的`addAdjacencies`功能后，这就是我们现在拥有的：

我`addAdjacencies`在添加更多功能的同时精简了。

通过删除颜色不匹配的节点，我们的算法可以100％确定`adjacentIds`支柱中的任何ID 都是连续的节点。

最后，我删除了没有相同颜色邻接的任何节点。这进一步简化了我们的算法，并且我们将总节点缩减到只有我们关心的那些节点。

错误的方式 - 递归
==========

TechLead表示我们无法递归地执行此算法，因为我们遇到了堆栈溢出。

虽然他部分正确，但有几种方法可以缓解这个问题。迭代或使用尾递归。我们将进入迭代示例，但JavaScript不再将尾递归作为本机语言功能。

虽然我们仍然可以在JavaScript中模拟尾递归，但我们将保持这种简单并创建一个典型的递归函数。

在我们点击代码之前，我们需要弄清楚我们的算法。对于递归，使用[深度优先搜索](https://en.wikipedia.org/wiki/Depth-first_search)是有意义的。不要担心知道计算机科学术语。当我向他展示我提出的不同解决方案时，一位同事说道。

算法
--

我们将从一个节点开始，尽可能地直到我们遇到一个端点。然后我们将回来并采取下一个分支路径，直到我们扫描整个连续块。

这是它的一部分。我们还必须跟踪我们去过的地方以及最大的连续区块的长度。

我所做的是将我们的功能分为两部分。一个人将保持最大列表和先前扫描的ID，同时至少循环每个节点一次。另一个将从未扫描的根节点开始并进行深度优先遍历。

这些是这些函数的样子：

疯了吧？我甚至辩论过显示代码，因为它变得如此粗糙。

为了减少这种情况，让我们一步一步走。

递归函数
----

`getContiguousIds`是我们的递归函数。每个节点调用一次。每次返回时，都会获得连续节点的更新列表。

此函数中只有一个条件：_我们的节点是否已在列表中？_如果没有，请`getContiguousIds`再次致电。当它返回时，我们将有一个连续节点的更新列表，它返回到我们的reducer并用作下一个节点的状态`adjacentId`。

您可能想知道我们在哪里添加值`contiguousIds`。当我们`concat`当前节点进入时会发生这种情况`contiguousIds`。每次我们进一步递归时，我们都要确保将当前节点添加到`contiguousIds`循环之前的列表中`adjacentIds`。

始终添加当前节点可确保我们不会无限递归。

循环
--

此函数的后半部分也会遍历每个节点一次。

我们有减速器围绕递归函数。这个检查我们的代码是否被扫描过。如果是这样，请继续循环，直到我们找到一个没有或直到我们退出循环的节点。

如果我们的节点尚未扫描，请致电`getContiguousIds`并等待完成。这是同步的，但可能需要一些时间。

一旦它返回列表`contiguousIds`，请检查列表中的那些`largestContiguousIds`。如果更大，则存储该值。

与此同时，我们将把这些添加`contiguousIds`到我们的`scannedIds`列表中以标记我们曾经去过的地方。

当你看到它全部布局时，这很简单。

执行
--

即使有10K项目，也没有遇到3种随机颜色的堆栈溢出问题。如果我改变所有内容以使用单一颜色，我就能够遇到堆栈溢出。那是因为我们的递归函数经历了10K递归。

顺序迭代
====

由于内存大于函数调用堆栈，我的下一个想法是在一个循环中完成整个事情。

我们将跟踪节点列表列表。我们将不断添加它们并将它们链接在一起，直到我们退出循环。

此方法要求我们将所有可能的节点列表保留在内存中，直到我们完成循环。在递归示例中，我们只将最大的列表保存在内存中。

另一个疯狂的。让我们从顶部打破这个。我们循环每个节点一次。但现在我们必须检查我们的id是否在节点列表列表中：`contiguousIdsList`。

如果它不在任何列表中`contiguousIds`，我们将添加它和它`adjacentIds`。这样，在循环时，其他东西将链接到它。

如果我们的节点在其中一个列表中，那么它可能就在其中的一些列表中。我们希望将所有这些链接在一起，并从中删除未链接的`contiguousIdsList`。

而已。

在我们提出节点列表列表之后，我们检查哪一个是最大的，我们就完成了。

执行
--

与递归版本不同，当所有10K项目的颜色相同时，此版本_会_完成。

除此之外，它很慢; 比我原先预期的要慢得多。我忘了考虑在我的绩效评估中循环列表列表，这显然会对性能产生影响。

随机迭代
====

我想采用递归方法背后的方法并迭代地应用它。

我花了一大晚的时间试图记住如何动态地改变循环中的索引然后我记得`while(true)`。我编写传统循环已经很久了，我完全忘记了它。

既然我拿到了我的武器，我就开始进攻了。由于我花了很多时间试图加速可观察的版本（稍后更多），我决定进入懒惰和老派变数数据。

这个算法的目标是只打一次每个节点，只存储最大的连续块：

即使我像大多数人一样写这篇文章，但它是迄今为止最不可读的。我甚至不能告诉你它是什么，如果没有自己首先从上到下。

我们没有添加到先前扫描的ID列表，而是从我们的`remainingNodes`数组中拼接出值。

懒！我不会建议你自己这样做，但我在绳子的最后创建这些样本，并想尝试不同的东西。

细分
--

我把它分成3个由`if`块分隔的部分。

让我们从中间部分开始。我们正在检查`queuedIds`。如果我们有一些，我们在排队的项目中进行另一个循环，看看它们是否属于我们的`remainingNodes`。

在第三部分，它取决于第二部分的结果。如果我们没有任何`queuedIds`，并`remainingNodesIndex`是`-1`，然后我们把这个节点列表完成，我们需要一个新的根节点开始。新的根节点始终处于索引状态，`0`因为我们正在拼接我们的节点`remainingNodes`。

回到循环的顶部，我可以使用`while(true)`，但我想要一个出路以防出现问题。这在调试时很有用，因为无限循环可能很难理解。

在那之后，我们正在拼接我们的节点。我们将它添加到我们的列表中`contiguousIds`，并将其添加`adjacentIds`到队列中。

执行
--

这最终几乎与递归版本一样快。当所有节点都是相同颜色时，它是所有算法中最快的。

特定于数据的优化
========

分组相似的颜色
-------

由于我们只知道蓝调与蓝调一致，我们可以将类似颜色的节点组合在一起用于顺序迭代版本。

将其拆分为3个较小的阵列可以降低我们的内存占用量以及我们需要在列表列表中执行的循环量。尽管如此，这并没有解决所有颜色都相同的情况，所以这不会修复我们的递归版本。

这也意味着我们可以对操作进行多线程处理，将执行时间缩短近三分之一。

如果我们按顺序执行这些，我们只需要先运行三个中最大的一个。如果最大值大于其他两个，则无需检查它们。

最大可能的大小
-------

我们可以检查每次迭代，而不是检查我们是否在某个时间间隔内有最大的列表。

如果最大集合大于或等于可用节点的一半（5K或更高），那么很明显我们已经拥有最大的节点。

使用随机迭代版本，我们可以找到目前为止最大的列表大小，并查看剩余的节点数。如果小于最大的尺寸，我们已经获得了最大的尺寸。

使用递归
----

虽然递归有其局限性，但我们仍然可以使用它。我们所要做的就是检查剩余节点的数量。如果它低于堆栈限制，我们可以切换到更快的递归版本。冒险，但随着你在循环中的进一步发展，它肯定会改善执行时间。

使用\`for\`循环
-----------

由于我们知道我们的最大项目数，因此将`reduce`功能切换到传统`for`循环会有一个小小的好处。

无论出于何种原因，[与](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)[循环](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)[相比](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)，`Array.prototype`方法[非常慢](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)。`[for](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)`[](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)

使用尾递归
-----

同样，我没有仔细阅读这篇特别文章中的可观察版本，我认为尾递归需要一篇自己的文章。

这是一个有很多要解释的重要主题，但是虽然它允许递归版本运行，但它可能不会`while`像你期望的那样比循环更快。

RxJS：可维护性与性能
============

有一些方法可以重写这些功能，您可以更轻松地理解和维护它们。我想出的主要解决方案是使用Redux-Observable风格的RxJS，但没有Redux。

这实际上是我对这篇文章的挑战。我想用常规方法编码，然后使用RxJS流式传输数据，看看我能推动多远。

我在RxJS中制作了3个版本并采取了一些自由来加快执行时间。与我的传感器文章不同，即使我增加行和列，所有三个都会变慢。

那个星期我花了我的夜晚梦想可能的解决方案并梳理每一寸代码。我甚至会躺在地上，闭上眼睛，想想想想。每一次，我都提出了更好的想法，但仍然受到JavaScript速度的限制。

我可以完成一整套优化，但代价是代码可读性。我不想那样（反正仍然使用过）。

我终于得到了一个可观察的解决方案 - 现在最快 - 在一半的时间内运行。这是总体上最好的改进。

我唯一能用可观察量击败内存繁重的连续迭代的时候是每个节点都是相同的颜色。那是唯一的一次。从技术上来说，它也会击败递归的，因为它在那种情况下会溢出。

在完成所有工作以确定如何使用RxJS传输数据之后，我意识到这对于这篇文章来说太过分了。期待未来的文章详细介绍这些代码示例。

如果你想早点看代码，你可以在GitHub上看到它：[https](https://github.com/Sawtaytoes/JavaScript-Performance-Interview-Question)：  
[//github.com/Sawtaytoes/JavaScript-Performance-Interview-Question](https://github.com/Sawtaytoes/JavaScript-Performance-Interview-Question)

最终统计数据
======

通常，最大的连续块平均为30-80个节点。

这些是我的数字：

无论我进行多少次测试，每种方法的相对位置都保持不变。

当所有节点都是相同颜色时，Redux-Observable Concurrent方法受到影响。我试了很多东西让它更快，但没有任何效果：/。

游戏开发
====

我在职业生涯中两次遇到过这段代码。在Lua，它的规模要小得多，并且在[我的独立游戏Pulsen](https://pulsengame.com/game)上工作时发生了。

在一种情况下，我正在制作世界地图。它有一个预定义的节点列表，我实时处理了这个列表。这使得击球`[LEFT]`，`[RIGHT]`，`[UP]`，和`[DOWN]`你走动的世界地图，即使是角度稍微偏离。

我还为具有X和Y值的未知项目列表编写了一个节点生成器。听起来有点熟？我还必须将屏幕中心放在屏幕上。在HTML中，这比使用游戏引擎更容易。虽然，以一堆绝对定位的div为中心也不容易。

在这两种解决方案中，实时执行时间并不是什么大问题，因为我在加载游戏时进行了大量的预处理。

我想强调，TechLead的问题可能是你在职业生涯中遇到的问题; 也许，但很少有速度成为典型JavaScript应用程序中的一个因素。

根据TechLeads的其他视频，他在谷歌使用Java。我假设他采访的职位关心执行速度。他们可能有一堆工作任务处理大量数据，所以这样的解决方案可能是必要的。

但是，它可能是一个致力于HTML和CSS的工作，他只是在拖拉受访者; 谁知道！

结论
==

正如您在最终统计数据中所看到的那样，最糟糕的代码几乎是最快的并且完成了我们所有的要求。祝你好运！

根据我自己的经验，我花了更长的时间来开发非RxJS版本。我认为这是因为更快的版本需要全面思考。Redux-Observable允许您以小块进行思考。

这是一个非常有趣且令人沮丧的问题。起初看起来真的很难，但是在把它分成几块之后，这些碎片都聚集在一起:)。

更多阅读
====

如果您想了解有关JavaScript性能的更多信息，请查看我的其他文章：

*   [加快JavaScript阵列处理速度](https://itnext.io/speed-up-javascript-array-processing-8d601c57bb0d)
*   [使用Transducers加速JavaScript数组](https://itnext.io/using-transducers-to-speed-up-javascript-arrays-92677d000096)

如果你喜欢你所读的内容，请查看我关于类似开眼话题的其他文章：

*   [回调：权威指南](https://itnext.io/the-definitive-guide-to-callbacks-in-javascript-44a39c065292)
*   [承诺：权威指南](https://itnext.io/promises-the-definitive-guide-6a49e0dbf3b7)
*   [功能标志：真正敏捷](https://itnext.io/feature-flags-be-truly-agile-820ff50294c)
*   [从食物Emojis制作大便](https://itnext.io/an-emoji-lovers-guide-to-functional-programming-part-1-241d8d4c9223)