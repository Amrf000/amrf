![频谱图卷积逐步解释和实施](https://towardsdatascience.com/spectral-graph-convolution-explained-and-implemented-step-by-step-2e495b57f801)
频谱图卷积逐步解释和实施
============

作为“计算机视觉及其他图形神经网络教程”的一部分
------------------------

[![鲍里斯Knyazev](https://miro.medium.com/fit/c/48/48/2*BsHNDApsus98YtJrnZkVPA.png)](/@BorisAKnyazev?source=post_page-----2e495b57f801----------------------)

[鲍里斯Knyazev](/@BorisAKnyazev?source=post_page-----2e495b57f801----------------------)

跟随

[8月16日](/spectral-graph-convolution-explained-and-implemented-step-by-step-2e495b57f801?source=post_page-----2e495b57f801----------------------) · 10 分钟阅读

![](https://miro.medium.com/max/30/1*Vx6uqv12rzb8HeUZl8d7-g.png?q=20)

左边的傅立叶基（DFT矩阵），其中每列或每行是基矢，重新形成28×28（右边），即右边显示20个基矢量。傅立叶基础用于计算谱卷积是信号处理。在图中，本文描述了拉普拉斯算法。

首先，让我们回想一下图表是什么。图_G_是由有向/无向**边**连接的一组**节点**（顶点）。在这篇文章中，我将假设一个带有_N个_节点的无向图_G._ 该图中的每个**节点**具有_C_维特征向量，并且所有节点的特征表示为_N_ × _C_维矩阵_X⁽ˡ⁾。_**图的边缘**表示为_N_ × _N_矩阵A，其中条目_Aᵢⱼ_表示节点_i_是否与节点连接（_相邻_）_j_。该矩阵称为_邻接矩阵_。

![](https://miro.medium.com/max/30/1*68Gcr70UTpdaX7THbZSEcA.png?q=20)

![](https://miro.medium.com/max/754/1*68Gcr70UTpdaX7THbZSEcA.png)

两个无向图，N = 5，N = 6个节点。节点的顺序是任意的。

图（见讲义的光谱分析[这里](http://www.cs.yale.edu/homes/spielman/561/)和早期的工作[在这里](https://papers.nips.cc/paper/1961-laplacian-eigenmaps-and-spectral-techniques-for-embedding-and-clustering)）一直是图聚类，社区发现和其他有用的_主要是无监督_的学习任务。在这篇文章中，我基本描述了[Bruna et al。，2014，ICLR 2014的工作](https://arxiv.org/abs/1312.6203)，他将光谱分析与卷积神经网络（ConvNets）相结合，产生了可以以_监督_方式训练的频谱**图卷积网络**，例如图分类任务。

尽管与_空间_图卷积方法相比，_谱图_卷积目前不太常用，但了解谱卷积如何工作仍有助于理解和避免其他方法的潜在问题。另外，在结论中我提到了一些最近激动人心的作品，使光谱图卷积更具竞争力。

图拉普拉斯算子和一点点物理学
==============

虽然“光谱”可能听起来很复杂，但就我们的目的来说，它足以理解它只是意味着_将_信号/音频/图像/图形分解为简单元素（小波，图形）的组合（通常是一个和）。为了具有这种_分解的_一些良好特性，这些简单元素通常是_正交的_，即相互线性独立的，因此形成_基础_。

当我们谈论信号/图像处理中的“光谱”时，我们暗示[傅里叶变换](https://en.wikipedia.org/wiki/Discrete_Fourier_transform)，它为我们提供了不同频率的基本正弦和余弦波的特定_基础_（例如在Python中的[DFT矩阵](https://en.wikipedia.org/wiki/DFT_matrix)`scipy.linalg.dft`），以便我们可以表示我们的信号/ image作为这些波的总和。但是，当我们谈论的图表和图形神经网络（GNNS），“光谱”暗示_特征分解_的的[**图形拉普拉斯**](https://en.wikipedia.org/wiki/Laplacian_matrix) _L._你可以把图形拉普拉斯的_大号_作为邻接矩阵_一个_以特殊的方式进行规范，而_本征分解_  是一种查找构成图形的基本正交分量的方法。

直观地，如果我们在节点_i中_放置一些“潜在的”，拉普拉斯图表示在什么方向以及“能量”将在图表上如何_平滑地_扩散。拉普拉斯算子在数学和物理学中的典型用例是解决信号（波）在动态系统中的传播方式。当邻居之间的值没有突然变化时，扩散是_平滑的_，如下面的动画中所示。

![](https://miro.medium.com/freeze/max/30/1*gz2hyrcSSJG9MtDzmQLe3w.gif?q=20)

在基于图拉普拉斯算子（[源](https://en.wikipedia.org/wiki/Laplacian_matrix)）计算的规则网格图中扩散某些信号（例如，它可以是热量）。基本上，计算这些动态所需的唯一事物是拉普拉斯算子和节点（像素）中的初始值，即对应于高强度（热量）的红色和黄色像素。

在帖子的其余部分，我将假设“ _对称归一化拉普拉斯算子_ ”，它经常用于图形神经网络，因为它被规范化，因此当您堆叠许多图层时，节点特征以更平滑的方式传播没有爆炸或消失的特征值或梯度。它_仅_基于图的邻接矩阵_A_计算，可以在几行Python代码中完成，如下所示：

**＃计算图形拉普拉斯  
＃A是一些曲线图的邻接矩阵_ģ_  
**进口numpy的作为NP N = A.shape \[0\] **中的图的节点＃数**  
 d = np.sum（A，0） **＃节点度**  
 D\_hat = NP .diag（（d + 1E-5）\*\*（ - 0.5）） **＃归一化节点度**  
 L = np.identity（N） - np.dot（D\_hat，A）.DOT（D\_hat） **＃拉普拉斯**

在这里，我们假设_一个_是对称的，即_一_ = _一_ ᵀ我们是无向图，否则节点度是不明确的，以及一些必须做出一些假设来计算拉普拉斯。邻接矩阵_A的_一个有趣特性是_Aⁿ_（矩阵乘积_n_次）暴露节点之间的_n-_ shop连接（有关详细信息，请参见[此处](https://en.wikipedia.org/wiki/Adjacency_matrix#Matrix_powers)）。

让我们生成三个图形并可视化它们的邻接矩阵和拉普拉斯算子以及它们的幂。

![](https://miro.medium.com/max/30/1*WSvWVAsQsGtQQpIcrCPOOQ.png?q=20)

邻接矩阵，拉普拉斯算子及其随机图的权力（左），“星图”（中）和“路径图”（右）。我将A 2标准化，使得每行中的和等于1，以便对2跳连接进行概率解释。请注意，拉普拉斯算子及其幂是对称矩阵，这使得特征分解更容易，并且有助于深度图网络中的特征传播。

例如，假设中间的上方星形图是由金属制成的，因此它可以很好地传递热量。然后，如果我们开始加热节点0（深蓝色），这个热量将以拉普拉斯算子定义的方式传播到其他节点。在所有边缘相等的星形图的特定情况下，热量将均匀地传播到所有其他节点，由于它们的结构，其他图形不是这样。

在计算机视觉和机器学习的背景下，拉普拉斯图形图定义了如果我们堆叠多个图形神经层，如何更新节点特征。与[_我的教程的第一部分_](https://medium.com/p/3d9fada3b80d)类似，为了从计算机视觉角度理解频谱图卷积，我将使用MNIST数据集，该数据集在28×28规则网格图上定义图像。

![](https://miro.medium.com/max/30/1*EUFjx4cvVq4TdmU1PfXRpA.png?q=20)

MNIST图像定义了常规28×28网格的特征X（左），邻接矩阵A（中）和拉普拉斯（右）。图拉普拉斯算子看起来像单位矩阵的原因是图具有相对大量的节点（784），因此在标准化之后，对角线外的值变得远小于1。

2.卷积
====

在信号处理中，可以表明空间域中的卷积是频域中的乘法（也称为[卷积定理](https://en.wikipedia.org/wiki/Convolution_theorem)）。相同的定理可以应用于图形。在信号处理中，为了将信号变换到频域，我们使用离散傅里叶变换，其基本上是具有特殊矩阵（基础，DFT矩阵）的信号的矩阵乘法。这个基础假设一个_规则_网格，所以我们不能将它用于_不规则_图形，这是一个典型的例子。相反，我们使用更一般的基础，即图拉普拉斯_L的_特征向量_V_，它可以通过特征分解找到：_L_ = _VΛVᵀ_，其中_Λ_是_L的_特征值

**PCA与图拉普拉斯算子的特征分解。**为了在实践中计算光谱图卷积，使用对应于_最小_特征值的一些特征向量就足够了。乍一看，与计算机视觉[主成分分析（PCA）中](https://en.wikipedia.org/wiki/Principal_component_analysis)经常使用的相比，它似乎是一种相反的策略，其中我们对与_最大_特征值对应的特征向量更感兴趣。然而，这种差异仅仅是由于用于计算上述拉普拉斯算子的_否定_，因此使用PCA计算的特征值与图Laplcacian的特征值_成反比_（参见[本文）](http://outobox.cs.umn.edu/PCA_on_a_Graph.pdf)进行正式分析）。还要注意，PCA应用于数据集的协方差矩阵，目的是提取最大的变化因子，即数据变化最大的维度，如特征[脸](https://en.wikipedia.org/wiki/Eigenface)。这种变化是通过特征值来测量的，因此最小的特征值基本上对应于噪声或“假”特征，这些特征在实践中被认为是无用的甚至是有害的。

![](https://miro.medium.com/max/30/1*k8AfLWuLW9sgOsuCarR19Q.png?q=20)

特征值（按降序排列）和MNIST数据集的相应特征向量。

图拉普拉斯算子的特征分解应用于单个图，以便提取节点的子图或集群（社区），[特征值告诉我们很多关于图连通性的信息](http://blog.shriphani.com/2015/04/06/the-smallest-eigenvalues-of-a-graph-laplacian/)。我将在下面的例子中使用对应于20个最小特征值的特征向量，假设20比节点_N_的数量小得多_（_在MNIST的情况下_N_ = 784 _）_。为了找到左边下方的特征值和特征向量，我使用28×28正则图，而在右边我按照[Bruna等人](https://arxiv.org/abs/1312.6203)的实验[。](https://arxiv.org/abs/1312.6203)并通过在28×28规则网格上采样400个随机位置来构建不规则图形（有关此实验的更多详细信息，请参阅其论文）。

![](https://miro.medium.com/max/30/1*93nVzwz_V7IPC7TPlgAsjQ.png?q=20)

根据[Bruna等，2014，ICLR 2014](https://arxiv.org/abs/1312.6203)（实验）中的实验，对于常规28 _×_ 28网格（**左**）和具有400个点的非均匀子采样网格的图拉普拉斯L的特征值_Λ（_**_底部_**_）和电子_传感器V（**顶部**）（**对**）。显示了对应于20个**最小****特征值的**特征向量。特征向量在左侧为784维，在右侧为400维，因此V分别为784 _×20和400×20。_左边的20个特征向量中的每一个被重新整形为28 _×_ 28，而在右边将400维特征向量重塑为28[](https://arxiv.org/abs/1312.6203) _×28，添加了缺失节点的白色像素。因此，_每个特征向量中的_e_像素对应于节点或缺失节点（右侧为白色）。这些特征向量可以被视为我们分解图形的基础。

因此，给定图拉普拉斯_L_，节点特征_X_和滤波器_W_ \_spectral，在Python中**，图上的谱卷积**看起来非常简单：

**图上的＃光谱卷积  
＃X是_1维的节点N×1矩阵的特征  
_****＃1** **是一个****_Ñ_** **_×N_上面计算图的拉普拉斯  
＃W\_spectral被****_Ñ_** **_×_** **_˚F权重（过滤器），我们希望培养  
_**从scipy.sparse。 linalg进口eigsh **＃假定_大号_是对称**_Λ_ _，V_ = eigsh（L，K = 20，这= 'SM'） **＃****特征分解（即找到_Λ_** **_，V）_**  
 X\_hat = VTdot（X） **＃_20_** **×** **_1_节点特征在“光谱”域中，**  
 W\_hat = VTdot（W\_spectral） **＃20× _F_****“频谱”域中的****滤波器**  
 Y = V.dot（X\_hat \* W\_hat） **\# _N_** **_×_** **_F_卷积结果**

形式上：

![](https://miro.medium.com/max/30/1*wBIfFw54z8usWq_merON8A.png?q=20)

频谱图卷积，其中⊙表示逐元素乘法。

在这里我们假设我们的节点功能_X⁽ˡ⁾_是一维的，例如MNIST像素，但它可以扩展到_ç_维案例：我们只需要重复此卷积对每个_信道_，然后总结了_Ç_作为信号/图像卷积。

公式（3）与使用傅里叶变换的[常规网格上的信号的频谱卷积](https://en.wikipedia.org/wiki/Convolution_theorem)基本相同，因此为机器学习产生了一些问题：

*   可训练权重（滤波器）_W\__谱的维数取决于图中节点_N_的数量;
*   _W\_ spectrum_还取决于在特征向量_V中_编码的图结构_。_

这些问题阻止了扩展到具有可变结构的大图的数据集。下文总结的进一步努力侧重于解决这些问题和其他问题。

**3.光谱域中的“平滑”**
===============

![](https://miro.medium.com/max/27/1*PcKEUB4wTOG6gtoEIZl9iA.png?q=20)

草莓和香蕉冰沙（来源：[joyfoodsunshine.com](https://joyfoodsunshine.com/strawberry-banana-smoothie/)）。光谱域中的平滑有点不同😃。

[布鲁纳等人。](https://arxiv.org/abs/1312.6203)是第一个应用光谱图分析来_学习_图分类问题的_卷积滤波器的人_之一。使用上面的公式（3）学习的过滤器作用于_整个图_，即它们具有_全局支持_。在计算机视觉环境中，这与在MNIST上训练大小为28×28像素的卷积滤波器相同，即滤波器具有与输入相同的大小（注意我们仍然会滑动滤波器，但是在零填充图像上） ）。虽然对于MNIST我们实际上可以训练这样的滤波器，常见的智慧建议避免这种情况，因为它使得训练更加困难，因为参数数量的潜在爆炸和训练大型滤波器的难度，这些滤波器可以捕获在不同图像之间共享的有用特征。

我实际上成功地使用PyTorch和我的GitHub中的[代码](https://github.com/bknyaz/examples/blob/master/fc_vs_graph_train.py)训练了这样的模型。你应该使用它来运行它`mnist_fc.py --model conv`。经过100个时期的训练后，过滤器看起来像数字的混合：

![](https://miro.medium.com/max/30/1*kNftNPG_J4i_pUN40DjAXQ.png?q=20)

具有**全局支持**的滤波器的示例通常用于频谱卷积。在这种情况下，这些是使用带有单个卷积层的ConvNet学习的28×28滤波器，其后是ReLU，7×7 MaxPooling和完全连接的分类层。为清楚起见，由于零填充，卷积层的输出仍为28×28。令人惊讶的是，该网络在MNIST上达到了96.7％。这可以通过数据集的简单性来解释。

重申一下，我们通常希望过滤器更小，更局部（这与我下面将要注意的不完全相同）。

为了暗示地强制执行，他们提出在频谱域中_平滑_滤波器，这使得它们根据频谱理论在空间域中_更加局部化_。我们的想法是，您可以将公式（3）中的滤波器_W\__谱表示为𝐾预定义函数（例如样条曲线）的总和，而不是学习_W的__N_值，我们学习此总和的_K_系数_α_：

![](https://miro.medium.com/max/30/1*sZoZfh6faYLBm7_Nq3xrQw.png?q=20)

我们可以将N维滤波器_W\_ spectrum_近似为_K_函数f 的有限和，例如下面所示的样条。因此，我们可以学习这些函数的K系数（alpha），而不是学习_W\__ spectral的N值; 当K << N时它变得有效。

虽然_fk_的维数确实取决于节点数_N_，但这些函数是固定的，因此我们不了解它们。我们知道的唯一的事情是系数_α_，所以_W\__光谱不再依赖_ñ_。干净吧？

![](https://miro.medium.com/max/30/1*DJWQBxMX3hZz85pKhma34w.png?q=20)

样条基础用于平滑频域中的滤波器，从而使它们更加局部化。样条函数和其他多项式函数很有用，因为我们可以将滤波器表示为它们的总和。

为了使公式（4）中的近似合理，我们希望_K_ << _N_将可训练参数的数量从_N_减少到_K_，更重要的是，使其独立于_N_，以便我们的GNN可以消化任何大小的图形。我们可以使用不同的基础来执行这种“扩展”，具体取决于我们需要的属性。例如，上面显示的三次样条函数称为非常平滑的函数（即，您无法看到节点，即分段样条多项式的各个部分相交的位置）。切比雪夫多项式，我在[另一篇文章中](https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49)讨论过[](https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49)，具有近似函数之间的最小𝑙∞距离。傅立叶基础是在转换后保留大部分信号能量的基础。大多数碱基是正交的，因为具有可以彼此表达的项是多余的。

请注意，滤波器_W\__ spectral仍然与输入一样大，但它们的_有效宽度_很小。在MNIST图像的情况下，我们将有28×28个滤波器，其中只有一小部分值具有大于0的绝对幅度，并且它们全部应该彼此靠近，即滤波器将是局部且有效的小的，类似于下面的那个（左起第二个）：

![](https://miro.medium.com/max/30/1*1NL_awIic9m5P-IF5_3J2A.png?q=20)

从左到右:(第一）输入图像。（秒）有效宽度小的局部滤波器。大多数值非常接近0.（第三）数字7和滤波器的MNIST图像的频谱图卷积的结果。（第四）使用傅立叶变换的频谱卷积的结果。这些结果表明，如果应用于图像，光谱图卷积可能是非常有限的，这可能是由于拉普拉斯基础的弱空间结构与傅里叶基础相比。

![](https://miro.medium.com/max/30/1*WtfLzUxDwyU8gwAD8u5HgQ.png?q=20)

X'= VV：使用傅立叶和图形拉普拉斯碱使用的V仅M个分量的图像MNIST重建_ᵀX_。我们可以看到，基础压缩图像中的不同模式（傅里叶情况下的定向边缘和拉普拉斯情况下的全局模式）。这使得上面说明的卷积结果非常不同。

总而言之，光谱域中的平滑允许[Bruna等人。](https://arxiv.org/abs/1312.6203)了解更多本地过滤器。具有这种滤波器的模型可以获得与没有平滑的模型（即使用我们的公式（3））类似的结果，但是具有更少的可训练参数，因为滤波器大小与输入图形大小无关，这对于缩放模型很重要到具有较大图形的数据集。然而，学习过滤器_W_ \_spectral仍然依赖于特征向量_V_，这使得将该模型应用于具有可变图结构的数据集具有挑战性。

结论
==

尽管原始光谱图卷积方法存在缺陷，但它已经开发了很多并且在某些应用中仍然是一种非常有竞争力的方法，因为光谱滤波器可以更好地捕获图形中的全局复杂模式，这些局部方法如GCN（[Kipf＆Welling， ICLR，2017](https://arxiv.org/abs/1609.02907)）除非堆放在深层网络中，否则不能。例如，[Liao等人的](https://arxiv.org/abs/1901.01484)两篇ICLR 2019年论文[。](https://arxiv.org/abs/1901.01484)在“LanczosNet”和[徐等人。](https://arxiv.org/abs/1904.07785)在“图形小波神经网络”上，解决了谱图卷积的一些缺点，并在预测分子特性和节点分类方面取得了很好的效果。[Levie等人的](https://arxiv.org/abs/1705.07664)另一项有趣的工作[，2018年](https://arxiv.org/abs/1705.07664)“CayleyNets”在节点分类，矩阵完成（推荐系统）和社区检测方面表现出色。因此，根据您的应用和基础设施，光谱图卷积可能是一个不错的选择。

在我[的计算机视觉及其他图形神经网络教程的](https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-2-be6d71d70f49)另一部分中，我解释了[Defferrard等人](https://arxiv.org/abs/1606.09375)介绍的Chebyshev谱图卷积[。](https://arxiv.org/abs/1606.09375)在2016年，这仍然是一个非常强大的基线，具有一些很好的属性，并且易于实现，因为我演示使用PyTorch。

_致谢：本教程的很大一部分是在我在SRI International实习期间在_[_Mohamed Amer_](/u/6cf41cb2c546?source=post_page-----2e495b57f801----------------------)_（_[_主页_](https://mohamedramer.com/)_）和我的博士生导师Graham Taylor（_[_主页_](https://www.gwtaylor.ca/)_）__的监督下准备的__。__我还要感谢_[_Carolyn Augusta_](https://www.linkedin.com/in/carolynaugusta/)_的有用反馈。_

在[Github](https://github.com/bknyaz/)，[LinkedIn](https://www.linkedin.com/in/boris-knyazev-39690948/)和[Twitter](https://twitter.com/BorisAKnyazev)上找到我。